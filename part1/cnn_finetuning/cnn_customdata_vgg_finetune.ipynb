{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# info \n",
    "Origin\n",
    "\n",
    "1) CNN에 대해서 \n",
    " - http://hunkim.github.io/ml/lec11.pdf\n",
    "\n",
    "2)Code Source\n",
    " - https://github.com/sjchoi86/Tensorflow-101\n",
    "\n",
    "\n",
    "Study Guideline\n",
    "\n",
    "1) CNN 이란 ? \n",
    "\n",
    "2) CNN 구현 \n",
    "\n",
    "3) cpu vs gpu ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"/usr/local/lib/python2.7/dist-packages\")\n",
    "\"\"\"\n",
    " Convolutional Neural Network (CNN) with Custom Data + vgg finetune\n",
    " @Sungjoon Choi (sungjoon.choi@cpslab.snu.ac.kr)\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc \n",
    "import scipy.io\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline  \n",
    "\n",
    "print (\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainlabel', 'trainimg', 'testimg', 'testlabel']\n",
      "[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "69 train images loaded\n",
      "18 test images loaded\n",
      "37632 dimensional input\n",
      "2 classes\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = current_time = datetime.datetime.now()\n",
    "\n",
    "# Load data\n",
    "cwd  = \"/home/ubuntu/work/data/tensor101\"\n",
    "loadpath = cwd + \"/data4vgg.npz\"\n",
    "l = np.load(loadpath)\n",
    "\n",
    "# Show Files\n",
    "print (l.files)\n",
    "\n",
    "# Parse data\n",
    "trainimg   = l['trainimg']\n",
    "trainlabel = l['trainlabel']\n",
    "testimg    = l['testimg']\n",
    "testlabel  = l['testlabel']\n",
    "# print trainimg\n",
    "print trainimg[0]\n",
    "# print trainlabel\n",
    "# print testimg\n",
    "# print testlabel\n",
    "\n",
    "ntrain     = trainimg.shape[0]\n",
    "nclass     = testlabel.shape[1]\n",
    "dim        = trainimg.shape[1]\n",
    "ntest      = testimg.shape[0]\n",
    "\n",
    "print (\"%d train images loaded\" % (ntrain))\n",
    "print (\"%d test images loaded\"  % (ntest))\n",
    "print (\"%d dimensional input\"   % (dim))\n",
    "print (\"%d classes\"             % (nclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21568627  0.23137255  0.03137255 ...,  0.90588235  0.78823529\n",
      "  0.67843137]\n",
      "shape of trainimg_tensor is (69, 112, 112, 3)\n",
      "[[[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.21568627  0.23137255  0.03137255]\n",
      "   [ 0.21960784  0.23921569  0.03529412]\n",
      "   [ 0.22745098  0.24705882  0.03529412]\n",
      "   ..., \n",
      "   [ 0.55686275  0.59607843  0.30980392]\n",
      "   [ 0.54901961  0.58039216  0.29803922]\n",
      "   [ 0.55294118  0.57647059  0.29411765]]\n",
      "\n",
      "  [[ 0.19215686  0.21960784  0.01568627]\n",
      "   [ 0.19607843  0.22352941  0.01960784]\n",
      "   [ 0.20392157  0.23137255  0.02352941]\n",
      "   ..., \n",
      "   [ 0.55294118  0.59215686  0.30980392]\n",
      "   [ 0.54901961  0.58431373  0.30588235]\n",
      "   [ 0.55294118  0.57647059  0.30196078]]\n",
      "\n",
      "  [[ 0.17647059  0.20392157  0.00392157]\n",
      "   [ 0.18039216  0.20784314  0.00784314]\n",
      "   [ 0.18823529  0.21568627  0.01176471]\n",
      "   ..., \n",
      "   [ 0.54509804  0.58431373  0.31372549]\n",
      "   [ 0.54901961  0.58431373  0.31372549]\n",
      "   [ 0.55686275  0.57647059  0.31372549]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.19215686  0.22745098  0.05882353]\n",
      "   [ 0.18039216  0.21568627  0.04705882]\n",
      "   [ 0.16862745  0.20392157  0.03529412]\n",
      "   ..., \n",
      "   [ 0.90980392  0.81568627  0.72941176]\n",
      "   [ 0.90980392  0.80392157  0.69803922]\n",
      "   [ 0.92156863  0.80784314  0.69019608]]\n",
      "\n",
      "  [[ 0.2         0.23137255  0.0627451 ]\n",
      "   [ 0.18823529  0.21960784  0.05098039]\n",
      "   [ 0.17254902  0.20784314  0.03921569]\n",
      "   ..., \n",
      "   [ 0.91372549  0.81568627  0.7254902 ]\n",
      "   [ 0.90588235  0.79607843  0.69411765]\n",
      "   [ 0.90980392  0.79215686  0.67843137]]\n",
      "\n",
      "  [[ 0.21176471  0.23921569  0.06666667]\n",
      "   [ 0.19607843  0.22352941  0.05098039]\n",
      "   [ 0.18039216  0.20784314  0.03529412]\n",
      "   ..., \n",
      "   [ 0.93333333  0.83137255  0.73333333]\n",
      "   [ 0.90980392  0.80784314  0.70196078]\n",
      "   [ 0.90588235  0.78823529  0.67843137]]]\n",
      "\n",
      "\n",
      " [[[ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  ..., \n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.67843137  0.68627451  0.68235294]\n",
      "   [ 0.67843137  0.68627451  0.68235294]\n",
      "   [ 0.67843137  0.68627451  0.68235294]\n",
      "   ..., \n",
      "   [ 0.82745098  0.85882353  0.87058824]\n",
      "   [ 0.82745098  0.85882353  0.87058824]\n",
      "   [ 0.82352941  0.85490196  0.86666667]]\n",
      "\n",
      "  [[ 0.68235294  0.69019608  0.68627451]\n",
      "   [ 0.68235294  0.69019608  0.68627451]\n",
      "   [ 0.68235294  0.69019608  0.68627451]\n",
      "   ..., \n",
      "   [ 0.82745098  0.85882353  0.87058824]\n",
      "   [ 0.82745098  0.85882353  0.87058824]\n",
      "   [ 0.82352941  0.85490196  0.86666667]]\n",
      "\n",
      "  [[ 0.67843137  0.69411765  0.69019608]\n",
      "   [ 0.67843137  0.69411765  0.69019608]\n",
      "   [ 0.67843137  0.69411765  0.69019608]\n",
      "   ..., \n",
      "   [ 0.82745098  0.85882353  0.87058824]\n",
      "   [ 0.82745098  0.85882353  0.87058824]\n",
      "   [ 0.82352941  0.85490196  0.86666667]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.88235294  0.89411765  0.92156863]\n",
      "   [ 0.88627451  0.89803922  0.9254902 ]\n",
      "   [ 0.89019608  0.90196078  0.92941176]\n",
      "   ..., \n",
      "   [ 0.74509804  0.74117647  0.71372549]\n",
      "   [ 0.7254902   0.72156863  0.70196078]\n",
      "   [ 0.7372549   0.74117647  0.72156863]]\n",
      "\n",
      "  [[ 0.88235294  0.89411765  0.92156863]\n",
      "   [ 0.88627451  0.89803922  0.9254902 ]\n",
      "   [ 0.89019608  0.90196078  0.92941176]\n",
      "   ..., \n",
      "   [ 0.72156863  0.72156863  0.69019608]\n",
      "   [ 0.7372549   0.7372549   0.71764706]\n",
      "   [ 0.78039216  0.78431373  0.76470588]]\n",
      "\n",
      "  [[ 0.88235294  0.89411765  0.92156863]\n",
      "   [ 0.88627451  0.89803922  0.9254902 ]\n",
      "   [ 0.89019608  0.90196078  0.92941176]\n",
      "   ..., \n",
      "   [ 0.70196078  0.69803922  0.67058824]\n",
      "   [ 0.75686275  0.75686275  0.7372549 ]\n",
      "   [ 0.78039216  0.78431373  0.76470588]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.2745098   0.27843137  0.29411765]\n",
      "   [ 0.29019608  0.29411765  0.30588235]\n",
      "   [ 0.30588235  0.30980392  0.31764706]\n",
      "   ..., \n",
      "   [ 0.56078431  0.53333333  0.50980392]\n",
      "   [ 0.52941176  0.50196078  0.47843137]\n",
      "   [ 0.50588235  0.47843137  0.45490196]]\n",
      "\n",
      "  [[ 0.27843137  0.28235294  0.29803922]\n",
      "   [ 0.29411765  0.29803922  0.30980392]\n",
      "   [ 0.30980392  0.31372549  0.32156863]\n",
      "   ..., \n",
      "   [ 0.56862745  0.54117647  0.51764706]\n",
      "   [ 0.54117647  0.51372549  0.49019608]\n",
      "   [ 0.51372549  0.48627451  0.4627451 ]]\n",
      "\n",
      "  [[ 0.28235294  0.28627451  0.30196078]\n",
      "   [ 0.29803922  0.30196078  0.31372549]\n",
      "   [ 0.31372549  0.32156863  0.32156863]\n",
      "   ..., \n",
      "   [ 0.58431373  0.55686275  0.53333333]\n",
      "   [ 0.55294118  0.5254902   0.50196078]\n",
      "   [ 0.5254902   0.49803922  0.4745098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.25882353  0.23137255  0.20784314]\n",
      "   [ 0.23921569  0.21568627  0.18823529]\n",
      "   [ 0.21568627  0.18823529  0.16470588]\n",
      "   ..., \n",
      "   [ 0.35686275  0.33333333  0.34117647]\n",
      "   [ 0.34901961  0.3254902   0.33333333]\n",
      "   [ 0.34117647  0.31764706  0.3254902 ]]\n",
      "\n",
      "  [[ 0.24705882  0.22745098  0.21568627]\n",
      "   [ 0.23921569  0.21960784  0.20784314]\n",
      "   [ 0.23137255  0.21176471  0.19607843]\n",
      "   ..., \n",
      "   [ 0.34901961  0.3254902   0.33333333]\n",
      "   [ 0.3372549   0.31372549  0.32156863]\n",
      "   [ 0.32941176  0.30588235  0.31372549]]\n",
      "\n",
      "  [[ 0.24705882  0.21960784  0.21176471]\n",
      "   [ 0.24705882  0.21960784  0.21176471]\n",
      "   [ 0.24705882  0.21960784  0.21176471]\n",
      "   ..., \n",
      "   [ 0.34117647  0.31764706  0.3254902 ]\n",
      "   [ 0.3372549   0.31372549  0.32156863]\n",
      "   [ 0.3254902   0.30196078  0.30980392]]]]\n",
      "shape of testimg_tensor is (18, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "#why chosen it this number ?\n",
    "# --> https://en.wikipedia.org/wiki/RGB_color_model#/media/File:Rgb-compose-Alim_Khan.jpg\n",
    "trainimg_tensor = np.ndarray((ntrain, 112, 112, 3))\n",
    "print trainimg[1, :]\n",
    "for i in range(ntrain):\n",
    "    currimg = trainimg[i, :]\n",
    "# what mean \"reshape\"\n",
    "# --> 각 tensor의 값 변경, 어떤 로직에 의해서?\n",
    "#  --> # 37632 개의 dimension을 W x H x D 형식으로 변경  \n",
    "    currimg = np.reshape(currimg, [112, 112, 3])\n",
    "    trainimg_tensor[i, :, :, :] = currimg \n",
    "print (\"shape of trainimg_tensor is %s\" % (trainimg_tensor.shape,))\n",
    "print trainimg_tensor \n",
    "\n",
    "testimg_tensor = np.ndarray((ntest, 112, 112, 3))\n",
    "for i in range(ntest):\n",
    "    currimg = testimg[i, :]\n",
    "    currimg = np.reshape(currimg, [112, 112, 3])\n",
    "    testimg_tensor[i, :, :, :] = currimg \n",
    "print (\"shape of testimg_tensor is %s\" % (testimg_tensor.shape,))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def net(data_path, input_image, data):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    print data.keys()\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "    weights = data['layers'][0]\n",
    "    \n",
    "#     print (\"mean_data :\", data)\n",
    "#     print (\"mean :\",  mean)\n",
    "#     print (\"mean_pixel:\", mean_pixel)\n",
    "#     print (\"weights:\", weights)\n",
    "\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(layers)\n",
    "    return net, mean_pixel\n",
    "\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "# def preprocess(image, mean_pixel):\n",
    "#     return image - mean_pixel\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layers', '__header__', '__globals__', 'classes', '__version__', 'normalization']\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "# what mean this file ? \n",
    "# -- > pre-trained model\n",
    "#       url=http://www.vlfeat.org/matconvnet/pretrained/\n",
    "cwd  = \"/home/ubuntu/work/data/tensor101\"\n",
    "VGG_PATH = cwd + \"/imagenet-vgg-verydeep-19.mat\"\n",
    "# 해당 데이터를 dictionary 형태로 가져옴\n",
    "data = scipy.io.loadmat(VGG_PATH)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=(None, 112, 112, 3))\n",
    "        net, mean_pixel = net(VGG_PATH, img_placeholder, data)\n",
    "        train_features = net['relu5_4'].eval(feed_dict={img_placeholder: trainimg_tensor})\n",
    "        test_features = net['relu5_4'].eval(feed_dict={img_placeholder: testimg_tensor})\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2725141  0.         0.        ...,  0.         0.5417695  0.       ]]\n",
      "[[ 0.23936665  0.          0.         ...,  0.76455289  0.66450101  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.20481074  0.        ]]\n",
      "[[ 0.3566516   0.          0.         ...,  0.          1.07389152  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.98639703  0.        ]]\n",
      "[[ 0.05062497  0.          0.         ...,  0.          0.85438609  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.31566834  0.        ]]\n",
      "[[ 0.3908186   0.          0.         ...,  0.          0.60115963  0.        ]]\n",
      "[[ 0.42308086  0.          0.         ...,  0.          1.11069465  0.        ]]\n",
      "[[ 0.53053486  0.          0.         ...,  0.          0.83186638  0.        ]]\n",
      "[[ 0.70621794  0.          0.         ...,  0.          1.29327285  0.        ]]\n",
      "[[ 0.02222145  0.          0.         ...,  0.          1.09890938  0.        ]]\n",
      "[[ 0.92214763  0.          0.         ...,  0.          1.33390403  0.        ]]\n",
      "[[ 0.3908186   0.          0.         ...,  0.          0.60115963  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.05346179  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.70307922  0.        ]]\n",
      "[[ 0.32868397  0.          0.         ...,  0.          0.74721891  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.15589237  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.30879462  0.        ]]\n",
      "[[ 0.70621794  0.          0.         ...,  0.          1.29327285  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.20481074  0.        ]]\n",
      "[[ 0.00287741  0.          0.         ...,  0.22585499  1.20151281  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.07684088  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.14898717  0.        ]]\n",
      "[[ 0.18497431  0.          0.33146423 ...,  0.          1.32934356  0.        ]]\n",
      "[[ 0.24674848  0.          0.         ...,  0.          1.46584582  0.        ]]\n",
      "[[ 0.23936665  0.          0.         ...,  0.76455289  0.66450101  0.        ]]\n",
      "[[ 0.3908186   0.          0.         ...,  0.          0.60115963  0.        ]]\n",
      "[[ 0.2553868   0.          0.         ...,  0.          1.13530517  0.        ]]\n",
      "[[ 0.31064874  0.          0.         ...,  0.          0.67818612  0.        ]]\n",
      "[[ 0.       0.       0.      ...,  0.       0.90537  0.     ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.23333979  0.        ]]\n",
      "[[ 0.52296239  0.          0.         ...,  0.          0.81389987  0.        ]]\n",
      "[[ 0.15847492  0.          0.         ...,  0.          1.18498302  0.        ]]\n",
      "[[ 0.12916225  0.          0.         ...,  0.          1.12877703  0.        ]]\n",
      "[[ 0.70621794  0.          0.         ...,  0.          1.29327285  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.77003402  0.        ]]\n",
      "[[ 0.27893245  0.          0.         ...,  0.          1.01965737  0.        ]]\n",
      "[[ 0.70621794  0.          0.         ...,  0.          1.29327285  0.        ]]\n",
      "[[ 0.12916225  0.          0.         ...,  0.          1.12877703  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.12813234  0.        ]]\n",
      "[[ 0.         0.         0.        ...,  0.         0.7838189  0.       ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.79031706  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.20481074  0.        ]]\n",
      "[[ 0.         0.         0.        ...,  0.         1.2606703  0.       ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.98639703  0.        ]]\n",
      "[[ 0.49953866  0.          0.         ...,  0.          1.38397121  0.        ]]\n",
      "[[ 0.18497431  0.          0.33146423 ...,  0.          1.32934356  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.02983284  0.        ]]\n",
      "[[ 0.62225693  0.          0.         ...,  0.          0.85419577  0.        ]]\n",
      "[[ 0.12916225  0.          0.         ...,  0.          1.12877703  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.95535022  0.        ]]\n",
      "[[ 0.32868397  0.          0.         ...,  0.          0.74721891  0.        ]]\n",
      "[[ 0.00287741  0.          0.         ...,  0.22585499  1.20151281  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.30879462  0.        ]]\n",
      "[[ 0.00437176  0.          0.         ...,  0.          0.89721721  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          0.97568959  0.        ]]\n",
      "[[ 0.15289217  0.          0.5165931  ...,  0.          0.75865793  0.        ]]\n",
      "[[ 0.32868397  0.          0.         ...,  0.          0.74721891  0.        ]]\n",
      "[[ 0.31064874  0.          0.         ...,  0.          0.67818612  0.        ]]\n",
      "[[ 0.78948247  0.          0.         ...,  0.          0.85414094  0.        ]]\n",
      "[[ 0.53053486  0.          0.         ...,  0.          0.83186638  0.        ]]\n",
      "[[ 0.78948247  0.          0.         ...,  0.          0.85414094  0.        ]]\n",
      "[[ 0.64563245  0.          0.         ...,  0.          0.68578309  0.        ]]\n",
      "[[ 0.18499285  0.          0.01233187 ...,  0.          0.35886678  0.        ]]\n",
      "[[ 0.78948247  0.          0.         ...,  0.          0.85414094  0.        ]]\n",
      "[[ 0.18567324  0.          0.         ...,  0.          0.98543584  0.        ]]\n",
      "[[ 0.          0.          0.         ...,  0.          1.15589237  0.        ]]\n",
      "[[ 0.24674848  0.          0.         ...,  0.          1.46584582  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize \n",
    "# what it's for ?\n",
    "# why chosen it this number '7 * 7* 512'?\n",
    "# --> 해당 상태에서의 W x H x D, W, H : spatial dim, D : filter\n",
    "train_vectorized = np.ndarray((ntrain, 7*7*512))\n",
    "test_vectorized  = np.ndarray((ntest, 7*7*512))\n",
    "for i in range(ntrain):\n",
    "    curr_feat = train_features[i, :, :, :]\n",
    "#     print curr_feat \n",
    "    curr_feat_vec = np.reshape(curr_feat, (1, -1))\n",
    "    print curr_feat_vec\n",
    "    train_vectorized[i, :] = curr_feat_vec\n",
    "    \n",
    "for i in range(ntest):\n",
    "    curr_feat = test_features[i, :, :, :]\n",
    "    curr_feat_vec = np.reshape(curr_feat, (1, -1))\n",
    "    test_vectorized[i, :] = curr_feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready to Go!\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# about learning_rate : https://github.com/seojey79/eml/blob/master/MNIST_perf.xlsx\n",
    "learning_rate   = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size      = 100\n",
    "display_step    = 10\n",
    "\n",
    "# Network\n",
    "# what is \"tf.device\" ?\n",
    "# --> using device \n",
    "#     --> avg(sec) : 88 vs 20\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    n_input  = dim\n",
    "    n_output = nclass \n",
    "    weights  = {\n",
    "        'wd1': tf.Variable(tf.random_normal([7*7*512, 1024], stddev=0.1)),\n",
    "        'wd2': tf.Variable(tf.random_normal([1024, n_output], stddev=0.1))\n",
    "    }\n",
    "    biases   = {\n",
    "        'bd1': tf.Variable(tf.random_normal([1024], stddev=0.1)),\n",
    "        'bd2': tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "    }\n",
    "    \n",
    "def conv_basic(_input, _w, _b, _keepratio):\n",
    "    # Input\n",
    "    _input_r = _input\n",
    "    # Vectorize\n",
    "    _dense1 = tf.reshape(_input_r, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "    # Fc1\n",
    "    _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w['wd1']), _b['bd1']))\n",
    "    _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)\n",
    "    # Fc2\n",
    "    _out = tf.add(tf.matmul(_fc_dr1, _w['wd2']), _b['bd2'])\n",
    "    # Return everything\n",
    "    out = {'input_r': _input_r, 'dense1': _dense1,\n",
    "        'fc1': _fc1, 'fc_dr1': _fc_dr1, 'out': _out }\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 7*7*512])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "# Functions! \n",
    "with tf.device(\"/gpu:0\"):\n",
    "    _pred = conv_basic(x, weights, biases, keepratio)['out']\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(_pred, y))\n",
    "    optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    _corr = tf.equal(tf.argmax(_pred,1), tf.argmax(y,1)) # Count corrects\n",
    "    accr = tf.reduce_mean(tf.cast(_corr, tf.float32)) # Accuracy\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "print (\"Network Ready to Go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/100 cost: 10.932435989\n",
      " Training accuracy: 0.180\n",
      " Test accuracy: 0.389\n",
      "Epoch: 010/100 cost: 1.962701321\n",
      " Training accuracy: 0.750\n",
      " Test accuracy: 0.500\n",
      "Epoch: 020/100 cost: 0.000944962\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.833\n",
      "Epoch: 030/100 cost: 0.000020276\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.833\n",
      "Epoch: 040/100 cost: 0.000000029\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.944\n",
      "Epoch: 050/100 cost: 0.000000001\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.944\n",
      "Epoch: 060/100 cost: 0.000000000\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.944\n",
      "Epoch: 070/100 cost: 0.000000000\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.944\n",
      "Epoch: 080/100 cost: 0.000000000\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.944\n",
      "Epoch: 090/100 cost: 0.000000000\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.944\n",
      "('Optimization Finished!, spent time : ', 21991.86618)\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    num_batch = int(ntrain/batch_size)+1\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch): \n",
    "        randidx  = np.random.randint(ntrain, size=batch_size)\n",
    "        batch_xs = train_vectorized[randidx, :]\n",
    "        batch_ys = trainlabel[randidx, :]     \n",
    "        # Fit training using batch data\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys, keepratio:0.7})\n",
    "        # Compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})/num_batch\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})\n",
    "        print (\" Training accuracy: %.3f\" % (train_acc))\n",
    "        test_acc = sess.run(accr, feed_dict={x: test_vectorized, y: testlabel, keepratio:1.})\n",
    "        print (\" Test accuracy: %.3f\" % (test_acc))\n",
    "\n",
    "end_time = current_time = datetime.datetime.now()       \n",
    "print (\"Optimization Finished!, spent time : \" , (end_time - start_time).total_seconds())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
