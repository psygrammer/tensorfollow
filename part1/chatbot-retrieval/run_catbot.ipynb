{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING FOR CHATBOTS [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머/텐서팔로우 - 파트 1 : 코드리뷰\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 리뷰 자료는 다음의 자료들과 코드를 거의 99.9% 활용함\n",
    "* [1] DEEP LEARNING FOR CHATBOTS, PART 1 – INTRODUCTION - http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/\n",
    "* [2] DEEP LEARNING FOR CHATBOTS, PART 2 – IMPLEMENTING A RETRIEVAL-BASED MODEL IN TENSORFLOW - http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "* [8] code - https://github.com/dennybritz/chatbot-retrieval/\n",
    "* [9] data - https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* PART 1 – INTRODUCTION\n",
    "    - Chatbots\n",
    "    - A TAXONOMY OF MODELS\n",
    "        - RETRIEVAL-BASED VS. GENERATIVE MODELS\n",
    "        - LONG VS. SHORT CONVERSATIONS\n",
    "        - OPEN DOMAIN VS. CLOSED DOMAIN\n",
    "    - COMMON CHALLENGES\n",
    "        - INCORPORATING CONTEXT\n",
    "        - COHERENT PERSONALITY\n",
    "        - EVALUATION OF MODELS\n",
    "        - INTENTION AND DIVERSITY\n",
    "    - HOW WELL DOES IT ACTUALLY WORK?\n",
    "    - UPCOMING & READING LIST\n",
    "* PART 2 – IMPLEMENTING A RETRIEVAL-BASED MODEL IN TENSORFLOW\n",
    "    - RETRIEVAL-BASED BOTS\n",
    "    - THE UBUNTU DIALOG CORPUS\n",
    "    - BASELINES\n",
    "    - DUAL ENCODER LSTM\n",
    "    - DATA PREPROCESSING\n",
    "    - CREATING AN INPUT FUNCTION\n",
    "    - DEFINING EVALUATION METRICS\n",
    "    - BOILERPLATE TRAINING CODE\n",
    "    - CREATING THE MODEL\n",
    "    - EVALUATING THE MODEL\n",
    "    - MAKING PREDICTIONS\n",
    "    - CONCLUSION\n",
    "* Code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 – INTRODUCTION\n",
    "* Chatbots\n",
    "* A TAXONOMY OF MODELS\n",
    "* COMMON CHALLENGES\n",
    "* HOW WELL DOES IT ACTUALLY WORK?\n",
    "* UPCOMING & READING LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* big bets - http://www.bloomberg.com/features/2016-microsoft-future-ai-chatbots/\n",
    "* Operator - https://operator.com/\n",
    "* x.ai - https://x.ai/\n",
    "* Chatfuel - http://chatfuel.com/\n",
    "* Howdy’s Botkit - http://howdy.ai/botkit/\n",
    "* Microsoft Bot Framework - https://dev.botframework.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A TAXONOMY OF MODELS\n",
    "* RETRIEVAL-BASED VS. GENERATIVE MODELS\n",
    "* LONG VS. SHORT CONVERSATIONS\n",
    "* OPEN DOMAIN VS. CLOSED DOMAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETRIEVAL-BASED VS. GENERATIVE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Retrieval-based models (easier)\n",
    "    - Retrieval-based models (easier) use a repository of predefined responses and some kind of heuristic to pick an appropriate response based on the input and context.\n",
    "    - These systems don’t generate any new text, they just pick a response from a fixed set.\n",
    "* Generative models (harder)\n",
    "    - Generative models (harder) don’t rely on pre-defined responses. They generate new responses from scratch.\n",
    "    <img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2016/04/nct-seq2seq.png\" width=600 />\n",
    "* Deep Learning\n",
    "    - Deep Learning techniques can be used for both retrieval-based or generative models, but research seems to be moving into the generative direction.\n",
    "    - Sequence to Sequence model - http://arxiv.org/abs/1409.3215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LONG VS. SHORT CONVERSATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Short-Text Conversations (easier)\n",
    "* long conversations (harder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN DOMAIN VS. CLOSED DOMAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* open domain (harder)\n",
    "    - There isn’t necessarily have a well-defined goal or intention.\n",
    "    - Conversations on social media sites like \n",
    "        - Twitter and \n",
    "        - Reddit are typically open domain \n",
    "            - they can go into all kinds of directions.\n",
    "* closed domain (easier) \n",
    "    - Technical Customer Support or \n",
    "    - Shopping Assistants\n",
    "        - These systems don’t need to be able to talk about politics, \n",
    "        - they just need to fulfill their specific task as efficiently as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMON CHALLENGES\n",
    "* INCORPORATING CONTEXT\n",
    "* COHERENT PERSONALITY\n",
    "* EVALUATION OF MODELS\n",
    "* INTENTION AND DIVERSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCORPORATING CONTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* linguistic context and physical context\n",
    "* embed - https://en.wikipedia.org/wiki/Word_embedding\n",
    "* Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models - http://arxiv.org/abs/1507.04808\n",
    "* Attention with Intention for a Neural Network Conversation Model - http://arxiv.org/abs/1510.08565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COHERENT PERSONALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* “How old are you?” and “What is your age?”\n",
    "* A Persona-Based Neural Conversation Model - http://arxiv.org/abs/1603.06155\n",
    "    <img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2016/04/Screen-Shot-2016-04-04-at-6.36.59-PM.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION OF MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BLEU - https://en.wikipedia.org/wiki/BLEU\n",
    "    - Common metrics such as BLEU that are used for Machine Translation and are based on text matching aren’t well suited because sensible responses can contain completely different words or phrases.\n",
    "    - 참고자료\n",
    "        - [3] Chapter 8. Evaluation (Statistical Machine Translation) - http://www.statmt.org/book/slides/08-evaluation.pdf\n",
    "        - [4] BLEU (wikipedia) - https://en.wikipedia.org/wiki/BLEU\n",
    "        - [5] BLEU (\"Show and Tell: A Neural Image Caption Generator (CVPR 2015) slide\") - https://docs.com/hana-lee/7849/show-and-tell-a-neural-image-caption-generator\n",
    "        - [6] BLEU (5. blue slide) - http://www.slideshare.net/hiroshimatsumoto750/5-bleu\n",
    "        - [7] Source code for nltk.align.bleu - http://www.nltk.org/_modules/nltk/align/bleu.html    \n",
    "* How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation - http://arxiv.org/abs/1603.08023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTENTION AND DIVERSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A common problem with generative systems is that they tend to produce generic responses like \n",
    "    - “That’s great!” or \n",
    "    - “I don’t know” that work for a lot of input cases.\n",
    "* Early versions of Google’s Smart Reply tended to respond with “I love you” to almost anything. \n",
    "    - Computer, respond to this email - https://research.googleblog.com/2015/11/computer-respond-to-this-email.html\n",
    "*  Some researchers have tried to artificially promote diversity through various objective functions\n",
    "    - A Diversity-Promoting Objective Function for Neural Conversation Models - http://arxiv.org/abs/1510.03055"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW WELL DOES IT ACTUALLY WORK?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A retrieval-based open domain system \n",
    "    - is obviously impossible because you can never handcraft enough responses to cover all cases. \n",
    "* A generative open-domain system \n",
    "    - is almost Artificial General Intelligence (AGI) because it needs to handle all possible scenarios. We’re very far away from that as well (but a lot of research is going on in that area).\n",
    "* This leaves us with problems in restricted domains where both generative and retrieval based methods are appropriate. \n",
    "* The longer the conversations and the more important the context, the more difficult the problem becomes.\n",
    "* In a recent interview, Andrew Ng\n",
    "    - Baidu research chief Andrew Ng fixed on self-taught computers, self-driving cars - http://www.seattletimes.com/business/baidu-research-chief-andrew-ng-fixed-on-self-taught-computers-self-driving-cars/\n",
    "    - \"<font color=\"red\">Most of the value of deep learning today is in narrow domains where you can get a lot of data. Here’s one example of something it cannot do: have a meaningful conversation. There are demos, and if you cherry-pick the conversation, it looks like it’s having a meaningful conversation, but if you actually try it yourself, it quickly goes off the rails.</font>\"\n",
    "* human workers & automate & big data\n",
    "* Grammatical mistakes\n",
    "    - retrieval-based models\n",
    "        - That’s why most systems are probably best off using retrieval-based methods that are free of grammatical errors and offensive responses. \n",
    "    - generative models\n",
    "        - If companies can somehow get their hands on huge amounts of data then generative models become feasible\n",
    "        -  but they must be assisted by other techniques to prevent them from going off the rails like Microsoft’s Tay did.\n",
    "            - Microsoft is deleting its AI chatbot's incredibly racist tweets - http://www.businessinsider.com/microsoft-deletes-racist-genocidal-tweets-from-ai-chatbot-tay-2016-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPCOMING & READING LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neural Responding Machine for Short-Text Conversation (2015-03) \n",
    "    - http://arxiv.org/abs/1503.02364\n",
    "* A Neural Conversational Model (2015-06)\n",
    "    - http://arxiv.org/abs/1506.05869\n",
    "* A Neural Network Approach to Context-Sensitive Generation of Conversational Responses (2015-06)\n",
    "    - http://arxiv.org/abs/1506.06714\n",
    "* The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems (2015-06)\n",
    "    - http://arxiv.org/abs/1506.08909\n",
    "* Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models (2015-07)\n",
    "    - http://arxiv.org/abs/1507.04808\n",
    "* A Diversity-Promoting Objective Function for Neural Conversation Models (2015-10)\n",
    "    - http://arxiv.org/abs/1510.03055\n",
    "* Attention with Intention for a Neural Network Conversation Model (2015-10)\n",
    "    - http://arxiv.org/abs/1510.08565\n",
    "* Improved Deep Learning Baselines for Ubuntu Corpus Dialogs (2015-10)\n",
    "    - http://arxiv.org/abs/1510.03753\n",
    "* A Survey of Available Corpora for Building Data-Driven Dialogue Systems (2015-12)\n",
    "    - http://arxiv.org/abs/1512.05742\n",
    "* Incorporating Copying Mechanism in Sequence-to-Sequence Learning (2016-03)\n",
    "    - http://arxiv.org/abs/1603.06393\n",
    "* A Persona-Based Neural Conversation Model (2016-03)\n",
    "    - http://arxiv.org/abs/1603.06155\n",
    "* How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation (2016-03)\n",
    "    - http://arxiv.org/abs/1603.08023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 – IMPLEMENTING A RETRIEVAL-BASED MODEL IN TENSORFLOW\n",
    "* RETRIEVAL-BASED BOTS\n",
    "* THE UBUNTU DIALOG CORPUS\n",
    "* BASELINES\n",
    "* DUAL ENCODER LSTM\n",
    "* DATA PREPROCESSING\n",
    "* CREATING AN INPUT FUNCTION\n",
    "* DEFINING EVALUATION METRICS\n",
    "* BOILERPLATE TRAINING CODE\n",
    "* CREATING THE MODEL\n",
    "* EVALUATING THE MODEL\n",
    "* MAKING PREDICTIONS\n",
    "* CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part2 tutorial info\n",
    "* This code uses Python 3 and Tensorflow >= 0.9.\n",
    "* numpy, scikit-learn, pandas\n",
    "* code - https://github.com/dennybritz/chatbot-retrieval/\n",
    "* data - https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRIEVAL-BASED BOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this post we’ll implement a retrieval-based bot. \n",
    "* The vast majority of production systems today are retrieval-based, or a combination of retrieval-based and generative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE UBUNTU DIALOG CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ubuntu Dialog Corpus \n",
    "    - paper : The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems - http://arxiv.org/abs/1506.08909\n",
    "    - github - https://github.com/rkadlec/ubuntu-ranking-dataset-creator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The training data consists of \n",
    "    - 1,000,000 examples, \n",
    "        - 50% positive (label 1) and \n",
    "        - 50% negative (label 0). \n",
    "    - Each example consists of \n",
    "        - a context, \n",
    "            - the conversation up to this point, and \n",
    "        - an utterance, \n",
    "            - a response to the context. \n",
    "    - A positive label means that \n",
    "        - an utterance was an actual response to a context, and \n",
    "    - a negative label means that \n",
    "        - the utterance wasn’t\n",
    "    - it was picked randomly from somewhere in the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"./notebooks/Data%20Exploration.ipynb\" />Here is some sample data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2016/04/Screen-Shot-2016-04-20-at-12.29.42-PM.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataset generation script has already done a bunch of preprocessing for us\n",
    "* tokenized - http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize\n",
    "* stemmed - http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.snowball\n",
    "* lemmatized - http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.wordnet\n",
    "* using the NLTK tool - http://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test / validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The format of these is different from that of the training data. \n",
    "* Each record in the test/validation set consists of \n",
    "    - a context, \n",
    "    - a ground truth utterance (the real response) and \n",
    "    - 9 incorrect utterances called \n",
    "        - distractors. \n",
    "* The goal of the model is to assign \n",
    "    - the highest score to the true utterance, and \n",
    "    - lower scores to wrong utterances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2016/04/Screen-Shot-2016-04-20-at-12.43.09-PM.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recall@k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* he are various ways to evaluate how well our model does. \n",
    "* A commonly used metric is recall@k. \n",
    "* Recall@k means that \n",
    "    - we let the model pick \n",
    "        - the k best responses out of \n",
    "        - the 10 possible responses \n",
    "            - (1 true and 9 distractors). \n",
    "    - If the correct one is among the picked ones we mark that test example as correct. \n",
    "    - So, a larger k \n",
    "        - means that the task becomes easier. \n",
    "    - If we set k=10 \n",
    "        - we get a recall of 100% \n",
    "            - because we only have 10 responses to pick from. \n",
    "    - If we set k=1 \n",
    "        - the model has only one chance to pick the right response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We’ll use the following function to evaluate our recall@k metric:\n",
    "def evaluate_recall(y, y_test, k=1):\n",
    "    num_examples = float(len(y))\n",
    "    num_correct = 0\n",
    "    for predictions, label in zip(y, y_test):\n",
    "        if label in predictions[:k]:\n",
    "            num_correct += 1\n",
    "    return num_correct/num_examples\n",
    "\n",
    "# Here, y is a list of our predictions \n",
    "# sorted by score in descending order,\n",
    "# and y_test is the actual label. \n",
    "# For example, \n",
    "# a y of [0,3,1,2,5,6,4,7,8,9] \n",
    "# Would mean that the utterance number 0 got the highest score, \n",
    "# and utterance 9 got the lowest score.\n",
    "\n",
    "# Remember that we have 10 utterances for each test example, \n",
    "# and the first one (index 0) is always the correct one \n",
    "# because the utterance column comes \n",
    "# before the distractor columns in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline (Random Predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, a completely random predictor should get \n",
    "* a score of 10% for recall@1, \n",
    "* a score of 20% for recall@2, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Predictor\n",
    "def predict_random(context, utterances):\n",
    "    return np.random.choice(len(utterances), 10, replace=False)\n",
    "\n",
    "# Evaluate Random predictor\n",
    "y_random = [predict_random(test_df.Context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]\n",
    "y_test = np.zeros(len(y_random))\n",
    "for n in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ ({}, 10): {:g}\".format(n, evaluate_recall(y_random, y_test, n)))\n",
    "    \n",
    "#Recall @ (1, 10): 0.0937632\n",
    "#Recall @ (2, 10): 0.194503\n",
    "#Recall @ (5, 10): 0.49297\n",
    "#Recall @ (10, 10): 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline (TF-IDF Predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another baseline that was discussed in the original paper is a tf-idf predictor.\n",
    "* tf-idf - https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "* scikit-learn - http://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TFIDFPredictor:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    " \n",
    "    def train(self, data):\n",
    "        self.vectorizer.fit(np.append(data.Context.values,data.Utterance.values))\n",
    " \n",
    "    def predict(self, context, utterances):\n",
    "        # Convert context and utterances into tfidf vector\n",
    "        vector_context = self.vectorizer.transform([context])\n",
    "        vector_doc = self.vectorizer.transform(utterances)\n",
    "        # The dot product measures the similarity of the resulting vectors\n",
    "        result = np.dot(vector_doc, vector_context.T).todense()\n",
    "        result = np.asarray(result).flatten()\n",
    "        # Sort by top results and return the indices in descending order\n",
    "        return np.argsort(result, axis=0)[::-1]\n",
    "# Evaluate TFIDF predictor\n",
    "pred = TFIDFPredictor()\n",
    "pred.train(train_df)\n",
    "y = [pred.predict(test_df.Context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]\n",
    "for n in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ ({}, 10): {:g}\".format(n, evaluate_recall(y, y_test, n)))\n",
    "\n",
    "\n",
    "#Recall @ (1, 10): 0.495032\n",
    "#Recall @ (2, 10): 0.596882\n",
    "#Recall @ (5, 10): 0.766121\n",
    "#Recall @ (10, 10): 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUAL ENCODER LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* seq2seq model - https://www.tensorflow.org/versions/r0.9/tutorials/seq2seq/index.html\n",
    "* Improved Deep Learning Baselines for Ubuntu Corpus Dialogs - http://arxiv.org/abs/1510.03753\n",
    "* The Dual Encoder LSTM \n",
    "    - The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems - http://arxiv.org/abs/1506.08909\n",
    "* library\n",
    "    - numpy - http://www.numpy.org/\n",
    "    - pandas - http://pandas.pydata.org/\n",
    "    - Tensorflow - http://www.tensorflow.org/\n",
    "    - TF Learn - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2016/04/Screen-Shot-2016-04-21-at-10.51.18-AM.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It roughly works as follows:\n",
    "1. Both the context and the response text \n",
    "    - are split by words, \n",
    "    - and each word is embedded into a vector. \n",
    "        - The word embeddings\n",
    "            - are initialized with Stanford’s GloVe vectors and \n",
    "            - are fine-tuned during training \n",
    "2. Both the embedded context and response \n",
    "    - are fed into the same Recurrent Neural Network word-by-word. \n",
    "    - The RNN generates a vector representation, \n",
    "        - c and r in the picture\n",
    "    - vector size : 256 dimensions.\n",
    "3. We multiply c with a matrix M to “predict” a response r'. \n",
    "    - If c is a 256-dimensional vector, then \n",
    "    -  M is a 256×256 dimensional matrix, and \n",
    "    - the result is another 256-dimensional vector, \n",
    "        - which we can interpret as a generated response. \n",
    "    - The matrix M is learned during training.\n",
    "4. We measure the similarity of \n",
    "    - the predicted response r' and the actual response r \n",
    "        - by taking the dot product of these two vectors. \n",
    "        - A large dot product means \n",
    "            - the vectors are similar and that \n",
    "            - the response should receive a high score. \n",
    "    - We then apply a sigmoid function \n",
    "        - to convert that score into a probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To train the network, we also need a loss (cost) function. \n",
    "* We’ll use the binary cross-entropy loss\n",
    "* True label for a context-response pair y. \n",
    "    - This can be either \n",
    "        - 1 (actual response) or \n",
    "        - 0 (incorrect response)\n",
    "* predicted probability y' (from step 4)\n",
    "* Then, the cross entropy loss is calculated as \n",
    "    - L= −y * ln(y') − (1 − y) * ln(1−y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset - https://github.com/rkadlec/ubuntu-ranking-dataset-creator\n",
    "* Tensorflow’s proprietary <font color=\"orange\">Example</font> format - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto\n",
    "    - There’s also tf.SequenceExample but it doesn’t seem to be supported by tf.learn yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vocabulary\n",
    "* As part of the preprocessing we also create a vocabulary. \n",
    "* This means we map each word to an integer number,\n",
    "    - e.g. “cat” may become 2631. \n",
    "* The TFRecord files we will generate store these integer numbers instead of the word strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each <font color=\"orange\">Example</font> contains the following fields:\n",
    "* context\n",
    "    -  A sequence of word ids representing the context text, \n",
    "    - e.g. [231, 2190, 737, 0, 912]\n",
    "* context_len\n",
    "    - The length of the context, \n",
    "    - e.g. 5 for the above example\n",
    "* utterance \n",
    "    - A sequence of word ids representing the utterance (response)\n",
    "* utterance_len\n",
    "    - The length of the utterance\n",
    "* label \n",
    "    - Only in the training data. \n",
    "    - 0 or 1.\n",
    "* distractor_[N]\n",
    "    - Only in the test/validation data. \n",
    "    - N ranges from 0 to 8. \n",
    "    - A sequence of word ids representing the distractor utterance.\n",
    "* distractor_[N]_len\n",
    "    - Only in the test/validation data. \n",
    "    - N ranges from 0 to 8. \n",
    "    - The length of the utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"orange\">prepare_data.py</font>\n",
    "    - The preprocessing is done by the prepare_data.py Python script\n",
    "    - which generates 3 files:\n",
    "        - train.tfrecords\n",
    "        - validation.tfrecords\n",
    "        - test.tfrecords  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING AN INPUT FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">udc_inputs.py</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "  # TODO Load and preprocess data here\n",
    "  return batched_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_input_fn(mode, input_files, batch_size, num_epochs=None):\n",
    "  def input_fn():\n",
    "    # TODO Load and preprocess data here\n",
    "    return batched_features, labels\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete code can be found in <font color=\"orange\">udc_inputs.py</font>. On a high level, the function does the following : \n",
    "1. Create a feature definition that describes the fields in our <font color=\"orange\">Example</font> file\n",
    "2. Read records from the <font color=\"blue\">input_files</font> with <font color=\"blue\">tf.TFRecordReader</font>\n",
    "3. Parse the records according to the feature definition\n",
    "4. Extract the training labels\n",
    "5. Batch multiple examples and training labels\n",
    "6. Return the batched examples and training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINING EVALUATION METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall@k metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_evaluation_metrics():\n",
    "  eval_metrics = {}\n",
    "  for k in [1, 2, 5, 10]:\n",
    "    eval_metrics[\"recall_at_%d\" % k] = functools.partial(\n",
    "        tf.contrib.metrics.streaming_sparse_recall_at_k,\n",
    "        k=k)\n",
    "  return eval_metrics\n",
    "\n",
    "# functools.partial\n",
    "#  - Above, we use functools.partial to convert a function \n",
    "#    that takes 3 arguments to one that only takes 2 arguments.\n",
    "\n",
    "# streaming_sparse_recall_at_k\n",
    "#  - Streaming just means that \n",
    "#    the metric is accumulated over multiple batches, \n",
    "#    and sparse refers to the format of our labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. [0.34, 0.11, 0.22, 0.45, 0.01, 0.02, 0.03, 0.08, 0.33, 0.11]\n",
    "* recall@1 ?\n",
    "* recall@2 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOILERPLATE TRAINING CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">udc_train.py</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let’s assume we have a model function \n",
    "# model_fn \n",
    "# that takes as inputs our batched features, \n",
    "# labels and mode (train or evaluation) \n",
    "# and returns the predictions.\n",
    "\n",
    "estimator = tf.contrib.learn.Estimator(\n",
    "model_fn=model_fn,\n",
    "model_dir=MODEL_DIR,\n",
    "config=tf.contrib.learn.RunConfig())\n",
    " \n",
    "input_fn_train = udc_inputs.create_input_fn(\n",
    "mode=tf.contrib.learn.ModeKeys.TRAIN,\n",
    "input_files=[TRAIN_FILE],\n",
    "batch_size=hparams.batch_size)\n",
    " \n",
    "input_fn_eval = udc_inputs.create_input_fn(\n",
    "mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "input_files=[VALIDATION_FILE],\n",
    "batch_size=hparams.eval_batch_size,\n",
    "num_epochs=1)\n",
    " \n",
    "eval_metrics = udc_metrics.create_evaluation_metrics()\n",
    " \n",
    "# We need to subclass theis manually for now. The next TF version will\n",
    "# have support ValidationMonitors with metrics built-in.\n",
    "# It's already on the master branch.\n",
    "class EvaluationMonitor(tf.contrib.learn.monitors.EveryN):\n",
    "def every_n_step_end(self, step, outputs):\n",
    "  self._estimator.evaluate(\n",
    "    input_fn=input_fn_eval,\n",
    "    metrics=eval_metrics,\n",
    "    steps=None)\n",
    " \n",
    "eval_monitor = EvaluationMonitor(every_n_steps=FLAGS.eval_every)\n",
    "estimator.fit(input_fn=input_fn_train, steps=None, monitors=[eval_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">hparams.py</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">hparams</font> is a custom object we create in hparams.py that holds hyperparameters, nobs we can tweak, of our model. This hparams object is given to the model when we instantiate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> dual_encoder.py</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_encoder_model(\n",
    "    hparams,\n",
    "    mode,\n",
    "    context,\n",
    "    context_len,\n",
    "    utterance,\n",
    "    utterance_len,\n",
    "    targets):\n",
    " \n",
    "  # Initialize embedidngs randomly or with pre-trained vectors if available\n",
    "  embeddings_W = get_embeddings(hparams)\n",
    " \n",
    "  # Embed the context and the utterance\n",
    "  context_embedded = tf.nn.embedding_lookup(\n",
    "      embeddings_W, context, name=\"embed_context\")\n",
    "  utterance_embedded = tf.nn.embedding_lookup(\n",
    "      embeddings_W, utterance, name=\"embed_utterance\")\n",
    " \n",
    " \n",
    "  # Build the RNN\n",
    "  with tf.variable_scope(\"rnn\") as vs:\n",
    "    # We use an LSTM Cell\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(\n",
    "        hparams.rnn_dim,\n",
    "        forget_bias=2.0,\n",
    "        use_peepholes=True,\n",
    "        state_is_tuple=True)\n",
    " \n",
    "    # Run the utterance and context through the RNN\n",
    "    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(\n",
    "        cell,\n",
    "        tf.concat(0, [context_embedded, utterance_embedded]),\n",
    "        sequence_length=tf.concat(0, [context_len, utterance_len]),\n",
    "        dtype=tf.float32)\n",
    "    encoding_context, encoding_utterance = tf.split(0, 2, rnn_states.h)\n",
    " \n",
    "  with tf.variable_scope(\"prediction\") as vs:\n",
    "    M = tf.get_variable(\"M\",\n",
    "      shape=[hparams.rnn_dim, hparams.rnn_dim],\n",
    "      initializer=tf.truncated_normal_initializer())\n",
    " \n",
    "    # \"Predict\" a  response: c * M\n",
    "    generated_response = tf.matmul(encoding_context, M)\n",
    "    generated_response = tf.expand_dims(generated_response, 2)\n",
    "    encoding_utterance = tf.expand_dims(encoding_utterance, 2)\n",
    " \n",
    "    # Dot product between generated response and actual response\n",
    "    # (c * M) * r\n",
    "    logits = tf.batch_matmul(generated_response, encoding_utterance, True)\n",
    "    logits = tf.squeeze(logits, [2])\n",
    " \n",
    "    # Apply sigmoid to convert logits to probabilities\n",
    "    probs = tf.sigmoid(logits)\n",
    " \n",
    "    # Calculate the binary cross-entropy loss\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits, tf.to_float(targets))\n",
    " \n",
    "  # Mean loss across the batch of examples\n",
    "  mean_loss = tf.reduce_mean(losses, name=\"mean_loss\")\n",
    "  return probs, mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this, we can now instantiate our model function in the main routine in <font color=\"orange\">udc_train.py</font> that we defined earlier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_fn = udc_model.create_model_fn(\n",
    "  hparams=hparams,\n",
    "  model_impl=dual_encoder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python udc_test.py --model_dir=$MODEL_DIR_FROM_TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. python udc_test.py --model_dir=~/github/chatbot-retrieval/runs/1467389151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you must call udc_test.py with the same parameters you used during training. So, if you trained with --embedding_size=128 you need to call the test script with the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for about 20,000 steps (around an hour on a fast GPU) our model gets the following results on the test set:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "recall_at_1 = 0.507581018519\n",
    "recall_at_2 = 0.689699074074\n",
    "recall_at_5 = 0.913020833333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* While recall@1 is close to our TFIDF model, recall@2 and recall@5 are significantly better, suggesting that our neural network assigns higher scores to the correct answers. \n",
    "* The original paper reported 0.55, 0.72 and 0.92 for recall@1, recall@2, and recall@5 respectively, \n",
    "    - but I haven’t been able to reproduce scores quite as high.\n",
    "    - Perhaps additional data preprocessing or hyperparameter optimization may bump scores up a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> udc_predict.py</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. python udc_predict.py --model_dir=./runs/1467576365/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outputs:\n",
    "\n",
    "Context: Example context\n",
    "Response 1: 0.44806\n",
    "Response 2: 0.481638"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could imagine feeding in 100 potential responses to a context and then picking the one with the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a lot of room for improvement, however. One can imagine that other neural networks do better on this task than a dual LSTM encoder. There is also a lot of room for hyperparameter optimization, or improvements to the preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  requirements.txt  udc_hparams.py  udc_model.py    udc_train.py\r\n",
      "models\t   run_catbot.ipynb  udc_inputs.py   udc_predict.py\r\n",
      "notebooks  scripts\t     udc_metrics.py  udc_test.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the train/dev/test data \n",
    "* here - https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM\n",
    "\n",
    "and extract the acrhive into ./data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  notebooks\t     scripts\t     udc_inputs.py   udc_predict.py\r\n",
      "data\t   requirements.txt  udc.tar.gz      udc_metrics.py  udc_test.py\r\n",
      "models\t   run_catbot.ipynb  udc_hparams.py  udc_model.py    udc_train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python udc_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Training steps [0,inf)\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Restored model from /root/work/chatbot-retrieval/runs/1468168955/model.ckpt-0-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 0.\n",
      "INFO:tensorflow:Results after 10 steps (7.210 sec/batch): recall_at_5 = 0.46875, recall_at_1 = 0.13125, loss = 6.2582, recall_at_10 = 1.0, recall_at_2 = 0.175.\n",
      "INFO:tensorflow:global_step/sec: 0.0082966\n",
      "INFO:tensorflow:Results after 20 steps (6.092 sec/batch): recall_at_5 = 0.5125, recall_at_1 = 0.13125, loss = 4.45727, recall_at_10 = 1.0, recall_at_2 = 0.196875.\n",
      "INFO:tensorflow:Results after 30 steps (5.952 sec/batch): recall_at_5 = 0.497916666667, recall_at_1 = 0.114583333333, loss = 6.53031, recall_at_10 = 1.0, recall_at_2 = 0.197916666667.\n",
      "INFO:tensorflow:Results after 40 steps (5.805 sec/batch): recall_at_5 = 0.4984375, recall_at_1 = 0.1140625, loss = 6.64572, recall_at_10 = 1.0, recall_at_2 = 0.196875.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Results after 50 steps (5.834 sec/batch): recall_at_5 = 0.4875, recall_at_1 = 0.12, loss = 3.9552, recall_at_10 = 1.0, recall_at_2 = 0.20875.\n",
      "INFO:tensorflow:Results after 60 steps (6.512 sec/batch): recall_at_5 = 0.497916666667, recall_at_1 = 0.123958333333, loss = 6.1875, recall_at_10 = 1.0, recall_at_2 = 0.214583333333.\n",
      "INFO:tensorflow:Results after 70 steps (6.427 sec/batch): recall_at_5 = 0.488392857143, recall_at_1 = 0.116964285714, loss = 6.23352, recall_at_10 = 1.0, recall_at_2 = 0.208928571429.\n",
      "INFO:tensorflow:Results after 80 steps (5.890 sec/batch): recall_at_5 = 0.4890625, recall_at_1 = 0.115625, loss = 6.00005, recall_at_10 = 1.0, recall_at_2 = 0.20546875.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Results after 90 steps (5.872 sec/batch): recall_at_5 = 0.484722222222, recall_at_1 = 0.111111111111, loss = 5.65793, recall_at_10 = 1.0, recall_at_2 = 0.202777777778.\n",
      "INFO:tensorflow:Results after 100 steps (2172.050 sec/batch): recall_at_5 = 0.485625, recall_at_1 = 0.115, loss = 5.84959, recall_at_10 = 1.0, recall_at_2 = 0.205.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Results after 110 steps (7.121 sec/batch): recall_at_5 = 0.488068181818, recall_at_1 = 0.117045454545, loss = 5.29503, recall_at_10 = 1.0, recall_at_2 = 0.202272727273.\n",
      "INFO:tensorflow:Results after 120 steps (5.942 sec/batch): recall_at_5 = 0.484375, recall_at_1 = 0.113541666667, loss = 5.23555, recall_at_10 = 1.0, recall_at_2 = 0.196354166667.\n",
      "INFO:tensorflow:Results after 130 steps (5.843 sec/batch): recall_at_5 = 0.482692307692, recall_at_1 = 0.113461538462, loss = 5.71813, recall_at_10 = 1.0, recall_at_2 = 0.195673076923.\n",
      "INFO:tensorflow:Results after 140 steps (5.837 sec/batch): recall_at_5 = 0.476339285714, recall_at_1 = 0.111607142857, loss = 6.3898, recall_at_10 = 1.0, recall_at_2 = 0.191964285714.\n",
      "INFO:tensorflow:Results after 150 steps (5.794 sec/batch): recall_at_5 = 0.474583333333, recall_at_1 = 0.113333333333, loss = 3.92448, recall_at_10 = 1.0, recall_at_2 = 0.190833333333.\n",
      "INFO:tensorflow:Results after 160 steps (7.295 sec/batch): recall_at_5 = 0.475, recall_at_1 = 0.11796875, loss = 5.2413, recall_at_10 = 1.0, recall_at_2 = 0.193359375.\n",
      "INFO:tensorflow:Results after 170 steps (7.094 sec/batch): recall_at_5 = 0.479044117647, recall_at_1 = 0.120588235294, loss = 5.24837, recall_at_10 = 1.0, recall_at_2 = 0.195220588235.\n",
      "INFO:tensorflow:Results after 180 steps (5.785 sec/batch): recall_at_5 = 0.480902777778, recall_at_1 = 0.122222222222, loss = 5.14225, recall_at_10 = 1.0, recall_at_2 = 0.197916666667.\n",
      "INFO:tensorflow:Results after 190 steps (6.995 sec/batch): recall_at_5 = 0.481907894737, recall_at_1 = 0.123355263158, loss = 5.09627, recall_at_10 = 1.0, recall_at_2 = 0.2.\n",
      "INFO:tensorflow:Results after 200 steps (7.094 sec/batch): recall_at_5 = 0.4846875, recall_at_1 = 0.125625, loss = 4.74566, recall_at_10 = 1.0, recall_at_2 = 0.2034375.\n",
      "INFO:tensorflow:Results after 210 steps (5.825 sec/batch): recall_at_5 = 0.485119047619, recall_at_1 = 0.12619047619, loss = 4.53883, recall_at_10 = 1.0, recall_at_2 = 0.203869047619.\n",
      "INFO:tensorflow:Results after 220 steps (7.067 sec/batch): recall_at_5 = 0.485795454545, recall_at_1 = 0.125568181818, loss = 6.81615, recall_at_10 = 1.0, recall_at_2 = 0.204545454545.\n",
      "INFO:tensorflow:Results after 230 steps (5853.433 sec/batch): recall_at_5 = 0.483967391304, recall_at_1 = 0.123913043478, loss = 5.82977, recall_at_10 = 1.0, recall_at_2 = 0.202173913043.\n",
      "INFO:tensorflow:Results after 240 steps (6.713 sec/batch): recall_at_5 = 0.4859375, recall_at_1 = 0.126041666667, loss = 5.79306, recall_at_10 = 1.0, recall_at_2 = 0.204427083333.\n",
      "INFO:tensorflow:Results after 250 steps (8.395 sec/batch): recall_at_5 = 0.4845, recall_at_1 = 0.12625, loss = 4.57585, recall_at_10 = 1.0, recall_at_2 = 0.20425.\n",
      "INFO:tensorflow:Results after 260 steps (7.893 sec/batch): recall_at_5 = 0.486057692308, recall_at_1 = 0.128365384615, loss = 6.36758, recall_at_10 = 1.0, recall_at_2 = 0.205769230769.\n",
      "INFO:tensorflow:Results after 270 steps (6.306 sec/batch): recall_at_5 = 0.486574074074, recall_at_1 = 0.128703703704, loss = 6.48735, recall_at_10 = 1.0, recall_at_2 = 0.205787037037.\n",
      "INFO:tensorflow:Results after 280 steps (6.142 sec/batch): recall_at_5 = 0.484151785714, recall_at_1 = 0.128348214286, loss = 5.76763, recall_at_10 = 1.0, recall_at_2 = 0.205133928571.\n",
      "INFO:tensorflow:Results after 290 steps (5.957 sec/batch): recall_at_5 = 0.483836206897, recall_at_1 = 0.129310344828, loss = 5.24917, recall_at_10 = 1.0, recall_at_2 = 0.205172413793.\n",
      "INFO:tensorflow:Results after 300 steps (6.020 sec/batch): recall_at_5 = 0.483958333333, recall_at_1 = 0.128958333333, loss = 5.9574, recall_at_10 = 1.0, recall_at_2 = 0.204583333333.\n",
      "INFO:tensorflow:Results after 310 steps (6.034 sec/batch): recall_at_5 = 0.486290322581, recall_at_1 = 0.128629032258, loss = 6.37728, recall_at_10 = 1.0, recall_at_2 = 0.204233870968.\n",
      "INFO:tensorflow:Results after 320 steps (6.104 sec/batch): recall_at_5 = 0.4890625, recall_at_1 = 0.1306640625, loss = 4.4665, recall_at_10 = 1.0, recall_at_2 = 0.2080078125.\n",
      "INFO:tensorflow:Results after 330 steps (6.015 sec/batch): recall_at_5 = 0.489583333333, recall_at_1 = 0.131439393939, loss = 4.96894, recall_at_10 = 1.0, recall_at_2 = 0.208522727273.\n",
      "INFO:tensorflow:Results after 340 steps (6.465 sec/batch): recall_at_5 = 0.488970588235, recall_at_1 = 0.130698529412, loss = 5.27414, recall_at_10 = 1.0, recall_at_2 = 0.207536764706.\n",
      "INFO:tensorflow:Results after 350 steps (6.287 sec/batch): recall_at_5 = 0.488571428571, recall_at_1 = 0.13125, loss = 5.28556, recall_at_10 = 1.0, recall_at_2 = 0.2075.\n",
      "INFO:tensorflow:Results after 360 steps (7.466 sec/batch): recall_at_5 = 0.488541666667, recall_at_1 = 0.130034722222, loss = 7.25517, recall_at_10 = 1.0, recall_at_2 = 0.20625.\n",
      "INFO:tensorflow:Results after 370 steps (6.255 sec/batch): recall_at_5 = 0.489358108108, recall_at_1 = 0.130067567568, loss = 6.21576, recall_at_10 = 1.0, recall_at_2 = 0.206418918919.\n",
      "INFO:tensorflow:Results after 380 steps (6.310 sec/batch): recall_at_5 = 0.490953947368, recall_at_1 = 0.130098684211, loss = 4.42828, recall_at_10 = 1.0, recall_at_2 = 0.206085526316.\n",
      "INFO:tensorflow:Results after 390 steps (5.954 sec/batch): recall_at_5 = 0.490705128205, recall_at_1 = 0.129807692308, loss = 4.70434, recall_at_10 = 1.0, recall_at_2 = 0.204807692308.\n",
      "INFO:tensorflow:Results after 400 steps (6.152 sec/batch): recall_at_5 = 0.49, recall_at_1 = 0.1303125, loss = 4.28289, recall_at_10 = 1.0, recall_at_2 = 0.2046875.\n",
      "INFO:tensorflow:Results after 410 steps (6.703 sec/batch): recall_at_5 = 0.49131097561, recall_at_1 = 0.131097560976, loss = 6.21821, recall_at_10 = 1.0, recall_at_2 = 0.206097560976.\n",
      "INFO:tensorflow:Results after 420 steps (6.228 sec/batch): recall_at_5 = 0.491369047619, recall_at_1 = 0.131101190476, loss = 4.50238, recall_at_10 = 1.0, recall_at_2 = 0.205357142857.\n",
      "INFO:tensorflow:Results after 430 steps (5.907 sec/batch): recall_at_5 = 0.492151162791, recall_at_1 = 0.131104651163, loss = 4.08255, recall_at_10 = 1.0, recall_at_2 = 0.205668604651.\n",
      "INFO:tensorflow:Results after 440 steps (7.331 sec/batch): recall_at_5 = 0.493465909091, recall_at_1 = 0.13125, loss = 6.34217, recall_at_10 = 1.0, recall_at_2 = 0.205965909091.\n",
      "INFO:tensorflow:Results after 450 steps (6.058 sec/batch): recall_at_5 = 0.492083333333, recall_at_1 = 0.131805555556, loss = 4.59248, recall_at_10 = 1.0, recall_at_2 = 0.206111111111.\n",
      "INFO:tensorflow:Results after 460 steps (6.135 sec/batch): recall_at_5 = 0.491168478261, recall_at_1 = 0.131385869565, loss = 6.32923, recall_at_10 = 1.0, recall_at_2 = 0.204755434783.\n",
      "INFO:tensorflow:Results after 470 steps (6.229 sec/batch): recall_at_5 = 0.491090425532, recall_at_1 = 0.131382978723, loss = 4.83126, recall_at_10 = 1.0, recall_at_2 = 0.205186170213.\n",
      "INFO:tensorflow:Results after 480 steps (6.794 sec/batch): recall_at_5 = 0.490885416667, recall_at_1 = 0.132161458333, loss = 5.45245, recall_at_10 = 1.0, recall_at_2 = 0.205729166667.\n",
      "INFO:tensorflow:Results after 490 steps (6.379 sec/batch): recall_at_5 = 0.491581632653, recall_at_1 = 0.132270408163, loss = 5.59284, recall_at_10 = 1.0, recall_at_2 = 0.205739795918.\n",
      "INFO:tensorflow:Results after 500 steps (6.358 sec/batch): recall_at_5 = 0.4925, recall_at_1 = 0.13225, loss = 6.47964, recall_at_10 = 1.0, recall_at_2 = 0.2055.\n",
      "INFO:tensorflow:Results after 510 steps (6.702 sec/batch): recall_at_5 = 0.492524509804, recall_at_1 = 0.132843137255, loss = 6.03441, recall_at_10 = 1.0, recall_at_2 = 0.205882352941.\n",
      "INFO:tensorflow:Results after 520 steps (6.491 sec/batch): recall_at_5 = 0.492908653846, recall_at_1 = 0.132692307692, loss = 5.14511, recall_at_10 = 1.0, recall_at_2 = 0.206009615385.\n",
      "INFO:tensorflow:Results after 530 steps (6.129 sec/batch): recall_at_5 = 0.492452830189, recall_at_1 = 0.13266509434, loss = 7.69217, recall_at_10 = 1.0, recall_at_2 = 0.206014150943.\n",
      "INFO:tensorflow:Results after 540 steps (6.154 sec/batch): recall_at_5 = 0.491782407407, recall_at_1 = 0.132291666667, loss = 5.80648, recall_at_10 = 1.0, recall_at_2 = 0.206018518519.\n",
      "INFO:tensorflow:Results after 550 steps (5.954 sec/batch): recall_at_5 = 0.491818181818, recall_at_1 = 0.131590909091, loss = 6.05631, recall_at_10 = 1.0, recall_at_2 = 0.205113636364.\n",
      "INFO:tensorflow:Results after 560 steps (6.881 sec/batch): recall_at_5 = 0.492410714286, recall_at_1 = 0.131473214286, loss = 6.05308, recall_at_10 = 1.0, recall_at_2 = 0.205357142857.\n",
      "INFO:tensorflow:Results after 570 steps (5.944 sec/batch): recall_at_5 = 0.493640350877, recall_at_1 = 0.131688596491, loss = 6.43502, recall_at_10 = 1.0, recall_at_2 = 0.206359649123.\n",
      "INFO:tensorflow:Results after 580 steps (7.117 sec/batch): recall_at_5 = 0.493426724138, recall_at_1 = 0.131142241379, loss = 4.88199, recall_at_10 = 1.0, recall_at_2 = 0.206357758621.\n",
      "INFO:tensorflow:Results after 590 steps (6.917 sec/batch): recall_at_5 = 0.493644067797, recall_at_1 = 0.131038135593, loss = 5.44174, recall_at_10 = 1.0, recall_at_2 = 0.205826271186.\n",
      "INFO:tensorflow:Results after 600 steps (6.490 sec/batch): recall_at_5 = 0.4934375, recall_at_1 = 0.131354166667, loss = 5.21974, recall_at_10 = 1.0, recall_at_2 = 0.20625.\n",
      "INFO:tensorflow:Results after 610 steps (6.626 sec/batch): recall_at_5 = 0.493135245902, recall_at_1 = 0.131045081967, loss = 6.59604, recall_at_10 = 1.0, recall_at_2 = 0.205840163934.\n",
      "INFO:tensorflow:Results after 620 steps (6.022 sec/batch): recall_at_5 = 0.492540322581, recall_at_1 = 0.130745967742, loss = 6.02115, recall_at_10 = 1.0, recall_at_2 = 0.205342741935.\n",
      "INFO:tensorflow:Results after 630 steps (5.787 sec/batch): recall_at_5 = 0.492658730159, recall_at_1 = 0.130654761905, loss = 5.30515, recall_at_10 = 1.0, recall_at_2 = 0.204861111111.\n",
      "INFO:tensorflow:Results after 640 steps (5.738 sec/batch): recall_at_5 = 0.49384765625, recall_at_1 = 0.1306640625, loss = 4.32371, recall_at_10 = 1.0, recall_at_2 = 0.2048828125.\n",
      "INFO:tensorflow:Results after 650 steps (7.073 sec/batch): recall_at_5 = 0.493461538462, recall_at_1 = 0.130576923077, loss = 5.89405, recall_at_10 = 1.0, recall_at_2 = 0.204807692308.\n",
      "INFO:tensorflow:Results after 660 steps (6.137 sec/batch): recall_at_5 = 0.49384469697, recall_at_1 = 0.131060606061, loss = 5.31938, recall_at_10 = 1.0, recall_at_2 = 0.205681818182.\n",
      "INFO:tensorflow:Results after 670 steps (6.216 sec/batch): recall_at_5 = 0.492910447761, recall_at_1 = 0.13078358209, loss = 6.10894, recall_at_10 = 1.0, recall_at_2 = 0.205130597015.\n",
      "INFO:tensorflow:Results after 680 steps (6.811 sec/batch): recall_at_5 = 0.493290441176, recall_at_1 = 0.130606617647, loss = 5.4016, recall_at_10 = 1.0, recall_at_2 = 0.205330882353.\n",
      "INFO:tensorflow:Results after 690 steps (8.955 sec/batch): recall_at_5 = 0.49375, recall_at_1 = 0.130615942029, loss = 6.46809, recall_at_10 = 1.0, recall_at_2 = 0.205344202899.\n",
      "INFO:tensorflow:Results after 700 steps (6.314 sec/batch): recall_at_5 = 0.493303571429, recall_at_1 = 0.13, loss = 6.6682, recall_at_10 = 1.0, recall_at_2 = 0.204821428571.\n",
      "INFO:tensorflow:Results after 710 steps (6.065 sec/batch): recall_at_5 = 0.492781690141, recall_at_1 = 0.129753521127, loss = 5.63396, recall_at_10 = 1.0, recall_at_2 = 0.204137323944.\n",
      "INFO:tensorflow:Results after 720 steps (5.996 sec/batch): recall_at_5 = 0.492795138889, recall_at_1 = 0.129947916667, loss = 5.18666, recall_at_10 = 1.0, recall_at_2 = 0.204253472222.\n",
      "INFO:tensorflow:Results after 730 steps (6.886 sec/batch): recall_at_5 = 0.493065068493, recall_at_1 = 0.130479452055, loss = 5.3651, recall_at_10 = 1.0, recall_at_2 = 0.20470890411.\n",
      "INFO:tensorflow:Results after 740 steps (6.259 sec/batch): recall_at_5 = 0.492989864865, recall_at_1 = 0.130489864865, loss = 5.99667, recall_at_10 = 1.0, recall_at_2 = 0.204814189189.\n",
      "INFO:tensorflow:Results after 750 steps (6.201 sec/batch): recall_at_5 = 0.493333333333, recall_at_1 = 0.1305, loss = 6.19208, recall_at_10 = 1.0, recall_at_2 = 0.20475.\n",
      "INFO:tensorflow:Results after 760 steps (6.107 sec/batch): recall_at_5 = 0.493256578947, recall_at_1 = 0.130674342105, loss = 5.05463, recall_at_10 = 1.0, recall_at_2 = 0.205098684211.\n",
      "INFO:tensorflow:Results after 770 steps (6.056 sec/batch): recall_at_5 = 0.493425324675, recall_at_1 = 0.130438311688, loss = 4.94101, recall_at_10 = 1.0, recall_at_2 = 0.205357142857.\n",
      "INFO:tensorflow:Results after 780 steps (6.823 sec/batch): recall_at_5 = 0.493108974359, recall_at_1 = 0.130448717949, loss = 4.48424, recall_at_10 = 1.0, recall_at_2 = 0.205128205128.\n",
      "INFO:tensorflow:Results after 790 steps (6.264 sec/batch): recall_at_5 = 0.493670886076, recall_at_1 = 0.131012658228, loss = 6.14445, recall_at_10 = 1.0, recall_at_2 = 0.205775316456.\n",
      "INFO:tensorflow:Results after 800 steps (6.291 sec/batch): recall_at_5 = 0.4934375, recall_at_1 = 0.13109375, loss = 5.69488, recall_at_10 = 1.0, recall_at_2 = 0.205625.\n",
      "INFO:tensorflow:Results after 810 steps (6.557 sec/batch): recall_at_5 = 0.493827160494, recall_at_1 = 0.13125, loss = 4.50974, recall_at_10 = 1.0, recall_at_2 = 0.205787037037.\n",
      "INFO:tensorflow:Results after 820 steps (6.371 sec/batch): recall_at_5 = 0.493445121951, recall_at_1 = 0.13125, loss = 6.25628, recall_at_10 = 1.0, recall_at_2 = 0.206021341463.\n",
      "INFO:tensorflow:Results after 830 steps (5.931 sec/batch): recall_at_5 = 0.494051204819, recall_at_1 = 0.132003012048, loss = 5.08068, recall_at_10 = 1.0, recall_at_2 = 0.206777108434.\n",
      "INFO:tensorflow:Results after 840 steps (5.988 sec/batch): recall_at_5 = 0.494791666667, recall_at_1 = 0.132217261905, loss = 4.75069, recall_at_10 = 1.0, recall_at_2 = 0.206994047619.\n",
      "INFO:tensorflow:Results after 850 steps (7.096 sec/batch): recall_at_5 = 0.494411764706, recall_at_1 = 0.132573529412, loss = 3.89905, recall_at_10 = 1.0, recall_at_2 = 0.207058823529.\n",
      "INFO:tensorflow:Results after 860 steps (6.356 sec/batch): recall_at_5 = 0.494840116279, recall_at_1 = 0.132485465116, loss = 5.99536, recall_at_10 = 1.0, recall_at_2 = 0.207194767442.\n",
      "INFO:tensorflow:Results after 870 steps (6.509 sec/batch): recall_at_5 = 0.495114942529, recall_at_1 = 0.13283045977, loss = 5.15607, recall_at_10 = 1.0, recall_at_2 = 0.207471264368.\n",
      "INFO:tensorflow:Results after 880 steps (6.987 sec/batch): recall_at_5 = 0.494602272727, recall_at_1 = 0.132457386364, loss = 6.76471, recall_at_10 = 1.0, recall_at_2 = 0.20703125.\n",
      "INFO:tensorflow:Results after 890 steps (7.055 sec/batch): recall_at_5 = 0.495435393258, recall_at_1 = 0.132584269663, loss = 5.42967, recall_at_10 = 1.0, recall_at_2 = 0.207584269663.\n",
      "INFO:tensorflow:Results after 900 steps (6.725 sec/batch): recall_at_5 = 0.495694444444, recall_at_1 = 0.132777777778, loss = 5.52527, recall_at_10 = 1.0, recall_at_2 = 0.208055555556.\n",
      "INFO:tensorflow:Results after 910 steps (6.316 sec/batch): recall_at_5 = 0.495260989011, recall_at_1 = 0.132623626374, loss = 5.33173, recall_at_10 = 1.0, recall_at_2 = 0.207760989011.\n",
      "INFO:tensorflow:Results after 920 steps (6.021 sec/batch): recall_at_5 = 0.495516304348, recall_at_1 = 0.132880434783, loss = 4.27153, recall_at_10 = 1.0, recall_at_2 = 0.207880434783.\n",
      "INFO:tensorflow:Results after 930 steps (6.529 sec/batch): recall_at_5 = 0.49563172043, recall_at_1 = 0.13313172043, loss = 5.09884, recall_at_10 = 1.0, recall_at_2 = 0.207997311828.\n",
      "INFO:tensorflow:Results after 940 steps (6.477 sec/batch): recall_at_5 = 0.495744680851, recall_at_1 = 0.133244680851, loss = 5.86185, recall_at_10 = 1.0, recall_at_2 = 0.207845744681.\n",
      "INFO:tensorflow:Results after 950 steps (6.445 sec/batch): recall_at_5 = 0.496447368421, recall_at_1 = 0.133421052632, loss = 5.22946, recall_at_10 = 1.0, recall_at_2 = 0.208355263158.\n",
      "INFO:tensorflow:Results after 960 steps (6.829 sec/batch): recall_at_5 = 0.496744791667, recall_at_1 = 0.133333333333, loss = 6.06019, recall_at_10 = 1.0, recall_at_2 = 0.208203125.\n",
      "INFO:tensorflow:Results after 970 steps (6.128 sec/batch): recall_at_5 = 0.497358247423, recall_at_1 = 0.132989690722, loss = 5.32046, recall_at_10 = 1.0, recall_at_2 = 0.207860824742.\n",
      "INFO:tensorflow:Results after 980 steps (6.343 sec/batch): recall_at_5 = 0.49693877551, recall_at_1 = 0.132844387755, loss = 3.98253, recall_at_10 = 1.0, recall_at_2 = 0.207461734694.\n",
      "INFO:tensorflow:Results after 990 steps (6.564 sec/batch): recall_at_5 = 0.496717171717, recall_at_1 = 0.132575757576, loss = 5.1746, recall_at_10 = 1.0, recall_at_2 = 0.207133838384.\n",
      "INFO:tensorflow:Results after 1000 steps (6.531 sec/batch): recall_at_5 = 0.497125, recall_at_1 = 0.1321875, loss = 4.69175, recall_at_10 = 1.0, recall_at_2 = 0.2069375.\n",
      "INFO:tensorflow:Results after 1010 steps (6.423 sec/batch): recall_at_5 = 0.496905940594, recall_at_1 = 0.131992574257, loss = 4.99305, recall_at_10 = 1.0, recall_at_2 = 0.206621287129.\n",
      "INFO:tensorflow:Results after 1020 steps (7.128 sec/batch): recall_at_5 = 0.49699754902, recall_at_1 = 0.132230392157, loss = 4.65253, recall_at_10 = 1.0, recall_at_2 = 0.206678921569.\n",
      "INFO:tensorflow:Results after 1030 steps (7.357 sec/batch): recall_at_5 = 0.496541262136, recall_at_1 = 0.13234223301, loss = 4.16165, recall_at_10 = 1.0, recall_at_2 = 0.206553398058.\n",
      "INFO:tensorflow:Results after 1040 steps (6.662 sec/batch): recall_at_5 = 0.496454326923, recall_at_1 = 0.132632211538, loss = 5.6782, recall_at_10 = 1.0, recall_at_2 = 0.206730769231.\n",
      "INFO:tensorflow:Results after 1050 steps (6.567 sec/batch): recall_at_5 = 0.497023809524, recall_at_1 = 0.132916666667, loss = 4.31912, recall_at_10 = 1.0, recall_at_2 = 0.207083333333.\n",
      "INFO:tensorflow:Results after 1060 steps (6.684 sec/batch): recall_at_5 = 0.496462264151, recall_at_1 = 0.132606132075, loss = 3.84165, recall_at_10 = 1.0, recall_at_2 = 0.206485849057.\n",
      "INFO:tensorflow:Results after 1070 steps (6.659 sec/batch): recall_at_5 = 0.496261682243, recall_at_1 = 0.132710280374, loss = 6.70531, recall_at_10 = 1.0, recall_at_2 = 0.20636682243.\n",
      "INFO:tensorflow:Results after 1080 steps (6.376 sec/batch): recall_at_5 = 0.496469907407, recall_at_1 = 0.133159722222, loss = 3.53879, recall_at_10 = 1.0, recall_at_2 = 0.206712962963.\n",
      "INFO:tensorflow:Results after 1090 steps (6.412 sec/batch): recall_at_5 = 0.496387614679, recall_at_1 = 0.133142201835, loss = 7.19056, recall_at_10 = 1.0, recall_at_2 = 0.206823394495.\n",
      "INFO:tensorflow:Results after 1100 steps (6.414 sec/batch): recall_at_5 = 0.496988636364, recall_at_1 = 0.133238636364, loss = 5.0926, recall_at_10 = 1.0, recall_at_2 = 0.206931818182.\n",
      "INFO:tensorflow:Results after 1110 steps (6.588 sec/batch): recall_at_5 = 0.497072072072, recall_at_1 = 0.133445945946, loss = 6.2299, recall_at_10 = 1.0, recall_at_2 = 0.207263513514.\n",
      "INFO:tensorflow:Input queue is exhausted.\n",
      "INFO:tensorflow:Step 1: mean_loss:0 = 3.31069\n",
      "INFO:tensorflow:training step 100, loss = 1.56241 (7.218 sec/batch).\n",
      "INFO:tensorflow:Step 101: mean_loss:0 = 1.75167\n",
      "INFO:tensorflow:training step 200, loss = 0.77892 (7.205 sec/batch).\n",
      "INFO:tensorflow:Step 201: mean_loss:0 = 0.865317\n",
      "INFO:tensorflow:training step 300, loss = 0.77670 (7.735 sec/batch).\n",
      "INFO:tensorflow:Step 301: mean_loss:0 = 0.874701\n",
      "INFO:tensorflow:training step 400, loss = 0.68178 (8.815 sec/batch).\n",
      "INFO:tensorflow:Step 401: mean_loss:0 = 0.693737\n",
      "INFO:tensorflow:training step 500, loss = 0.69270 (6.698 sec/batch).\n",
      "INFO:tensorflow:Step 501: mean_loss:0 = 0.689216\n",
      "INFO:tensorflow:training step 600, loss = 0.68259 (7.967 sec/batch).\n",
      "INFO:tensorflow:Step 601: mean_loss:0 = 0.701364\n",
      "INFO:tensorflow:training step 700, loss = 0.71359 (6.674 sec/batch).\n",
      "INFO:tensorflow:Step 701: mean_loss:0 = 0.696547\n",
      "INFO:tensorflow:training step 800, loss = 0.68053 (6.826 sec/batch).\n",
      "INFO:tensorflow:Step 801: mean_loss:0 = 0.675662\n",
      "INFO:tensorflow:training step 900, loss = 0.67745 (6.856 sec/batch).\n",
      "INFO:tensorflow:Step 901: mean_loss:0 = 0.649074\n",
      "INFO:tensorflow:training step 1000, loss = 0.69495 (8.052 sec/batch).\n",
      "INFO:tensorflow:Step 1001: mean_loss:0 = 0.7192\n",
      "INFO:tensorflow:training step 1100, loss = 0.68694 (6.714 sec/batch).\n",
      "INFO:tensorflow:Step 1101: mean_loss:0 = 0.680104\n",
      "INFO:tensorflow:training step 1200, loss = 0.67740 (6.817 sec/batch).\n",
      "INFO:tensorflow:Step 1201: mean_loss:0 = 0.713796\n",
      "INFO:tensorflow:training step 1300, loss = 0.68289 (6.762 sec/batch).\n",
      "INFO:tensorflow:Step 1301: mean_loss:0 = 0.696655\n",
      "INFO:tensorflow:training step 1400, loss = 0.66747 (7.266 sec/batch).\n",
      "INFO:tensorflow:Step 1401: mean_loss:0 = 0.68917\n",
      "INFO:tensorflow:training step 1500, loss = 0.71461 (7.272 sec/batch).\n",
      "INFO:tensorflow:Step 1501: mean_loss:0 = 0.685394\n",
      "INFO:tensorflow:training step 1600, loss = 0.66091 (6.833 sec/batch).\n",
      "INFO:tensorflow:Step 1601: mean_loss:0 = 0.681474\n",
      "INFO:tensorflow:training step 1700, loss = 0.67103 (7.305 sec/batch).\n",
      "INFO:tensorflow:Step 1701: mean_loss:0 = 0.668386\n",
      "INFO:tensorflow:training step 1800, loss = 0.64894 (6.966 sec/batch).\n",
      "INFO:tensorflow:Step 1801: mean_loss:0 = 0.644294\n",
      "INFO:tensorflow:training step 1900, loss = 0.67846 (7.199 sec/batch).\n",
      "INFO:tensorflow:Step 1901: mean_loss:0 = 0.688935\n",
      "INFO:tensorflow:training step 2000, loss = 0.66874 (7.722 sec/batch).\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Restored model from /root/work/chatbot-retrieval/runs/1468168955/model.ckpt-1981-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 1981.\n",
      "INFO:tensorflow:Results after 10 steps (6.263 sec/batch): recall_at_5 = 0.675, recall_at_1 = 0.225, loss = 0.634249, recall_at_10 = 1.0, recall_at_2 = 0.29375.\n",
      "INFO:tensorflow:Results after 20 steps (6.313 sec/batch): recall_at_5 = 0.703125, recall_at_1 = 0.2, loss = 0.599356, recall_at_10 = 1.0, recall_at_2 = 0.3375.\n",
      "INFO:tensorflow:Results after 30 steps (5.891 sec/batch): recall_at_5 = 0.6875, recall_at_1 = 0.2, loss = 0.617685, recall_at_10 = 1.0, recall_at_2 = 0.335416666667.\n",
      "INFO:tensorflow:Results after 40 steps (5.966 sec/batch): recall_at_5 = 0.6609375, recall_at_1 = 0.1890625, loss = 0.614544, recall_at_10 = 1.0, recall_at_2 = 0.321875.\n",
      "INFO:tensorflow:Results after 50 steps (1236.704 sec/batch): recall_at_5 = 0.665, recall_at_1 = 0.185, loss = 0.607815, recall_at_10 = 1.0, recall_at_2 = 0.3275.\n",
      "INFO:tensorflow:Results after 60 steps (6.264 sec/batch): recall_at_5 = 0.666666666667, recall_at_1 = 0.182291666667, loss = 0.655268, recall_at_10 = 1.0, recall_at_2 = 0.325.\n",
      "INFO:tensorflow:Results after 70 steps (6.767 sec/batch): recall_at_5 = 0.666964285714, recall_at_1 = 0.185714285714, loss = 0.672893, recall_at_10 = 1.0, recall_at_2 = 0.330357142857.\n",
      "INFO:tensorflow:Results after 80 steps (6.660 sec/batch): recall_at_5 = 0.66953125, recall_at_1 = 0.1921875, loss = 0.600246, recall_at_10 = 1.0, recall_at_2 = 0.33203125.\n",
      "INFO:tensorflow:Results after 90 steps (5.905 sec/batch): recall_at_5 = 0.665277777778, recall_at_1 = 0.189583333333, loss = 0.616097, recall_at_10 = 1.0, recall_at_2 = 0.330555555556.\n",
      "INFO:tensorflow:Results after 100 steps (5.949 sec/batch): recall_at_5 = 0.67, recall_at_1 = 0.1925, loss = 0.638778, recall_at_10 = 1.0, recall_at_2 = 0.335.\n",
      "INFO:tensorflow:Results after 110 steps (6.452 sec/batch): recall_at_5 = 0.672159090909, recall_at_1 = 0.195454545455, loss = 0.587473, recall_at_10 = 1.0, recall_at_2 = 0.334659090909.\n",
      "INFO:tensorflow:Results after 120 steps (7.290 sec/batch): recall_at_5 = 0.675, recall_at_1 = 0.197916666667, loss = 0.589804, recall_at_10 = 1.0, recall_at_2 = 0.336979166667.\n",
      "INFO:tensorflow:Results after 130 steps (5.879 sec/batch): recall_at_5 = 0.670673076923, recall_at_1 = 0.191826923077, loss = 0.628188, recall_at_10 = 1.0, recall_at_2 = 0.328365384615.\n",
      "INFO:tensorflow:Results after 140 steps (6.487 sec/batch): recall_at_5 = 0.669196428571, recall_at_1 = 0.189285714286, loss = 0.676056, recall_at_10 = 1.0, recall_at_2 = 0.324553571429.\n",
      "INFO:tensorflow:Results after 150 steps (6.049 sec/batch): recall_at_5 = 0.669583333333, recall_at_1 = 0.189583333333, loss = 0.639255, recall_at_10 = 1.0, recall_at_2 = 0.324166666667.\n",
      "INFO:tensorflow:Results after 160 steps (5.996 sec/batch): recall_at_5 = 0.669140625, recall_at_1 = 0.191015625, loss = 0.662962, recall_at_10 = 1.0, recall_at_2 = 0.325390625.\n",
      "INFO:tensorflow:Results after 170 steps (6.018 sec/batch): recall_at_5 = 0.667647058824, recall_at_1 = 0.188970588235, loss = 0.629405, recall_at_10 = 1.0, recall_at_2 = 0.325.\n",
      "INFO:tensorflow:Results after 180 steps (5.992 sec/batch): recall_at_5 = 0.664583333333, recall_at_1 = 0.190277777778, loss = 0.624963, recall_at_10 = 1.0, recall_at_2 = 0.325694444444.\n",
      "INFO:tensorflow:Results after 190 steps (6.191 sec/batch): recall_at_5 = 0.662828947368, recall_at_1 = 0.1875, loss = 0.627845, recall_at_10 = 1.0, recall_at_2 = 0.323355263158.\n",
      "INFO:tensorflow:Results after 200 steps (6.122 sec/batch): recall_at_5 = 0.665, recall_at_1 = 0.18875, loss = 0.620509, recall_at_10 = 1.0, recall_at_2 = 0.3259375.\n",
      "INFO:tensorflow:Results after 210 steps (6.234 sec/batch): recall_at_5 = 0.66755952381, recall_at_1 = 0.1875, loss = 0.630656, recall_at_10 = 1.0, recall_at_2 = 0.324702380952.\n",
      "INFO:tensorflow:Results after 220 steps (6.180 sec/batch): recall_at_5 = 0.667897727273, recall_at_1 = 0.188068181818, loss = 0.654066, recall_at_10 = 1.0, recall_at_2 = 0.326988636364.\n",
      "INFO:tensorflow:Results after 230 steps (6.143 sec/batch): recall_at_5 = 0.667663043478, recall_at_1 = 0.186141304348, loss = 0.617676, recall_at_10 = 1.0, recall_at_2 = 0.327717391304.\n",
      "INFO:tensorflow:Results after 240 steps (6.420 sec/batch): recall_at_5 = 0.667708333333, recall_at_1 = 0.185677083333, loss = 0.64813, recall_at_10 = 1.0, recall_at_2 = 0.328385416667.\n",
      "INFO:tensorflow:Results after 250 steps (6.250 sec/batch): recall_at_5 = 0.66775, recall_at_1 = 0.18675, loss = 0.61001, recall_at_10 = 1.0, recall_at_2 = 0.32925.\n",
      "INFO:tensorflow:Results after 260 steps (6.195 sec/batch): recall_at_5 = 0.666586538462, recall_at_1 = 0.186778846154, loss = 0.67169, recall_at_10 = 1.0, recall_at_2 = 0.328365384615.\n",
      "INFO:tensorflow:Results after 270 steps (6.118 sec/batch): recall_at_5 = 0.665277777778, recall_at_1 = 0.187731481481, loss = 0.633029, recall_at_10 = 1.0, recall_at_2 = 0.328472222222.\n",
      "INFO:tensorflow:Results after 280 steps (5.937 sec/batch): recall_at_5 = 0.666294642857, recall_at_1 = 0.187946428571, loss = 0.63657, recall_at_10 = 1.0, recall_at_2 = 0.328348214286.\n",
      "INFO:tensorflow:Results after 290 steps (6.402 sec/batch): recall_at_5 = 0.666379310345, recall_at_1 = 0.189224137931, loss = 0.591413, recall_at_10 = 1.0, recall_at_2 = 0.330172413793.\n",
      "INFO:tensorflow:Results after 300 steps (6.258 sec/batch): recall_at_5 = 0.666666666667, recall_at_1 = 0.190208333333, loss = 0.645519, recall_at_10 = 1.0, recall_at_2 = 0.331666666667.\n",
      "INFO:tensorflow:Results after 310 steps (6.142 sec/batch): recall_at_5 = 0.665322580645, recall_at_1 = 0.188508064516, loss = 0.621019, recall_at_10 = 1.0, recall_at_2 = 0.329435483871.\n",
      "INFO:tensorflow:Results after 320 steps (6.394 sec/batch): recall_at_5 = 0.663671875, recall_at_1 = 0.1884765625, loss = 0.622989, recall_at_10 = 1.0, recall_at_2 = 0.3294921875.\n",
      "INFO:tensorflow:Results after 330 steps (6.515 sec/batch): recall_at_5 = 0.662310606061, recall_at_1 = 0.188636363636, loss = 0.600814, recall_at_10 = 1.0, recall_at_2 = 0.329166666667.\n",
      "INFO:tensorflow:Results after 340 steps (6.291 sec/batch): recall_at_5 = 0.661029411765, recall_at_1 = 0.188051470588, loss = 0.621249, recall_at_10 = 1.0, recall_at_2 = 0.329411764706.\n",
      "INFO:tensorflow:Results after 350 steps (5.897 sec/batch): recall_at_5 = 0.662678571429, recall_at_1 = 0.187678571429, loss = 0.637378, recall_at_10 = 1.0, recall_at_2 = 0.330714285714.\n",
      "INFO:tensorflow:Results after 360 steps (6.236 sec/batch): recall_at_5 = 0.662326388889, recall_at_1 = 0.187152777778, loss = 0.628083, recall_at_10 = 1.0, recall_at_2 = 0.329513888889.\n",
      "INFO:tensorflow:Results after 370 steps (6.227 sec/batch): recall_at_5 = 0.6625, recall_at_1 = 0.1875, loss = 0.637687, recall_at_10 = 1.0, recall_at_2 = 0.32972972973.\n",
      "INFO:tensorflow:Results after 380 steps (6.180 sec/batch): recall_at_5 = 0.6625, recall_at_1 = 0.187006578947, loss = 0.611527, recall_at_10 = 1.0, recall_at_2 = 0.328947368421.\n",
      "INFO:tensorflow:Results after 390 steps (6.091 sec/batch): recall_at_5 = 0.661378205128, recall_at_1 = 0.186538461538, loss = 0.668578, recall_at_10 = 1.0, recall_at_2 = 0.328846153846.\n",
      "INFO:tensorflow:Results after 400 steps (6.232 sec/batch): recall_at_5 = 0.6596875, recall_at_1 = 0.18578125, loss = 0.611607, recall_at_10 = 1.0, recall_at_2 = 0.32734375.\n",
      "INFO:tensorflow:Results after 410 steps (5.906 sec/batch): recall_at_5 = 0.660823170732, recall_at_1 = 0.186432926829, loss = 0.602834, recall_at_10 = 1.0, recall_at_2 = 0.327591463415.\n",
      "INFO:tensorflow:Results after 420 steps (6.108 sec/batch): recall_at_5 = 0.660714285714, recall_at_1 = 0.18630952381, loss = 0.629054, recall_at_10 = 1.0, recall_at_2 = 0.326339285714.\n",
      "INFO:tensorflow:Results after 430 steps (6.775 sec/batch): recall_at_5 = 0.660029069767, recall_at_1 = 0.187354651163, loss = 0.634743, recall_at_10 = 1.0, recall_at_2 = 0.327034883721.\n",
      "INFO:tensorflow:Results after 440 steps (6.251 sec/batch): recall_at_5 = 0.660511363636, recall_at_1 = 0.187926136364, loss = 0.59194, recall_at_10 = 1.0, recall_at_2 = 0.327698863636.\n",
      "INFO:tensorflow:Results after 450 steps (6.452 sec/batch): recall_at_5 = 0.660277777778, recall_at_1 = 0.187361111111, loss = 0.601049, recall_at_10 = 1.0, recall_at_2 = 0.328333333333.\n",
      "INFO:tensorflow:Results after 460 steps (5.872 sec/batch): recall_at_5 = 0.660869565217, recall_at_1 = 0.186956521739, loss = 0.665031, recall_at_10 = 1.0, recall_at_2 = 0.327038043478.\n",
      "INFO:tensorflow:Results after 470 steps (7.251 sec/batch): recall_at_5 = 0.659973404255, recall_at_1 = 0.187765957447, loss = 0.62081, recall_at_10 = 1.0, recall_at_2 = 0.327792553191.\n",
      "INFO:tensorflow:Results after 480 steps (6.401 sec/batch): recall_at_5 = 0.66015625, recall_at_1 = 0.186848958333, loss = 0.613166, recall_at_10 = 1.0, recall_at_2 = 0.326953125.\n",
      "INFO:tensorflow:Results after 490 steps (6.253 sec/batch): recall_at_5 = 0.658545918367, recall_at_1 = 0.186607142857, loss = 0.618323, recall_at_10 = 1.0, recall_at_2 = 0.326530612245.\n",
      "INFO:tensorflow:Results after 500 steps (6.062 sec/batch): recall_at_5 = 0.65875, recall_at_1 = 0.18675, loss = 0.581166, recall_at_10 = 1.0, recall_at_2 = 0.326875.\n",
      "INFO:tensorflow:Results after 510 steps (5.978 sec/batch): recall_at_5 = 0.658578431373, recall_at_1 = 0.186519607843, loss = 0.625797, recall_at_10 = 1.0, recall_at_2 = 0.326838235294.\n",
      "INFO:tensorflow:Results after 520 steps (6.189 sec/batch): recall_at_5 = 0.659254807692, recall_at_1 = 0.188100961538, loss = 0.620133, recall_at_10 = 1.0, recall_at_2 = 0.328125.\n",
      "INFO:tensorflow:Results after 530 steps (5.888 sec/batch): recall_at_5 = 0.657193396226, recall_at_1 = 0.186674528302, loss = 0.626038, recall_at_10 = 1.0, recall_at_2 = 0.325825471698.\n",
      "INFO:tensorflow:Results after 540 steps (6.440 sec/batch): recall_at_5 = 0.655902777778, recall_at_1 = 0.186226851852, loss = 0.652011, recall_at_10 = 1.0, recall_at_2 = 0.325347222222.\n",
      "INFO:tensorflow:Results after 550 steps (6.056 sec/batch): recall_at_5 = 0.656136363636, recall_at_1 = 0.185340909091, loss = 0.664235, recall_at_10 = 1.0, recall_at_2 = 0.324090909091.\n",
      "INFO:tensorflow:Results after 560 steps (5.965 sec/batch): recall_at_5 = 0.656808035714, recall_at_1 = 0.186495535714, loss = 0.635087, recall_at_10 = 1.0, recall_at_2 = 0.324441964286.\n",
      "INFO:tensorflow:Results after 570 steps (6.217 sec/batch): recall_at_5 = 0.657675438596, recall_at_1 = 0.186074561404, loss = 0.638714, recall_at_10 = 1.0, recall_at_2 = 0.325.\n",
      "INFO:tensorflow:Results after 580 steps (6.248 sec/batch): recall_at_5 = 0.658405172414, recall_at_1 = 0.186206896552, loss = 0.628635, recall_at_10 = 1.0, recall_at_2 = 0.324892241379.\n",
      "INFO:tensorflow:Results after 590 steps (6.102 sec/batch): recall_at_5 = 0.658474576271, recall_at_1 = 0.185805084746, loss = 0.635893, recall_at_10 = 1.0, recall_at_2 = 0.324788135593.\n",
      "INFO:tensorflow:Results after 600 steps (6.368 sec/batch): recall_at_5 = 0.6584375, recall_at_1 = 0.185625, loss = 0.615958, recall_at_10 = 1.0, recall_at_2 = 0.325104166667.\n",
      "INFO:tensorflow:Results after 610 steps (6.211 sec/batch): recall_at_5 = 0.657889344262, recall_at_1 = 0.185758196721, loss = 0.645994, recall_at_10 = 1.0, recall_at_2 = 0.325102459016.\n",
      "INFO:tensorflow:Results after 620 steps (6.061 sec/batch): recall_at_5 = 0.658165322581, recall_at_1 = 0.186592741935, loss = 0.661809, recall_at_10 = 1.0, recall_at_2 = 0.326209677419.\n",
      "INFO:tensorflow:Results after 630 steps (6.045 sec/batch): recall_at_5 = 0.657341269841, recall_at_1 = 0.18630952381, loss = 0.607172, recall_at_10 = 1.0, recall_at_2 = 0.325595238095.\n",
      "INFO:tensorflow:Results after 640 steps (6.037 sec/batch): recall_at_5 = 0.65751953125, recall_at_1 = 0.18671875, loss = 0.591472, recall_at_10 = 1.0, recall_at_2 = 0.32587890625.\n",
      "INFO:tensorflow:Results after 650 steps (6.133 sec/batch): recall_at_5 = 0.657115384615, recall_at_1 = 0.1875, loss = 0.617899, recall_at_10 = 1.0, recall_at_2 = 0.32625.\n",
      "INFO:tensorflow:Results after 660 steps (6.224 sec/batch): recall_at_5 = 0.657765151515, recall_at_1 = 0.187026515152, loss = 0.66705, recall_at_10 = 1.0, recall_at_2 = 0.326704545455.\n",
      "INFO:tensorflow:Results after 670 steps (6.342 sec/batch): recall_at_5 = 0.657649253731, recall_at_1 = 0.186847014925, loss = 0.600891, recall_at_10 = 1.0, recall_at_2 = 0.326865671642.\n",
      "INFO:tensorflow:Results after 680 steps (6.044 sec/batch): recall_at_5 = 0.657169117647, recall_at_1 = 0.186488970588, loss = 0.635205, recall_at_10 = 1.0, recall_at_2 = 0.3265625.\n",
      "INFO:tensorflow:Results after 690 steps (6.015 sec/batch): recall_at_5 = 0.656612318841, recall_at_1 = 0.186594202899, loss = 0.650557, recall_at_10 = 1.0, recall_at_2 = 0.326721014493.\n",
      "INFO:tensorflow:Results after 700 steps (6.175 sec/batch): recall_at_5 = 0.656607142857, recall_at_1 = 0.186696428571, loss = 0.648665, recall_at_10 = 1.0, recall_at_2 = 0.326696428571.\n",
      "INFO:tensorflow:Results after 710 steps (5.952 sec/batch): recall_at_5 = 0.657922535211, recall_at_1 = 0.187059859155, loss = 0.644115, recall_at_10 = 1.0, recall_at_2 = 0.32676056338.\n",
      "INFO:tensorflow:Results after 720 steps (6.027 sec/batch): recall_at_5 = 0.657638888889, recall_at_1 = 0.187152777778, loss = 0.675745, recall_at_10 = 1.0, recall_at_2 = 0.326822916667.\n",
      "INFO:tensorflow:Results after 730 steps (6.071 sec/batch): recall_at_5 = 0.657534246575, recall_at_1 = 0.186729452055, loss = 0.614015, recall_at_10 = 1.0, recall_at_2 = 0.326369863014.\n",
      "INFO:tensorflow:Results after 740 steps (6.047 sec/batch): recall_at_5 = 0.657094594595, recall_at_1 = 0.186824324324, loss = 0.604981, recall_at_10 = 1.0, recall_at_2 = 0.32660472973.\n",
      "INFO:tensorflow:Results after 750 steps (6.042 sec/batch): recall_at_5 = 0.656916666667, recall_at_1 = 0.186916666667, loss = 0.613733, recall_at_10 = 1.0, recall_at_2 = 0.327083333333.\n",
      "INFO:tensorflow:Results after 760 steps (5.870 sec/batch): recall_at_5 = 0.657976973684, recall_at_1 = 0.187006578947, loss = 0.601028, recall_at_10 = 1.0, recall_at_2 = 0.327384868421.\n",
      "INFO:tensorflow:Results after 770 steps (5.871 sec/batch): recall_at_5 = 0.658685064935, recall_at_1 = 0.187175324675, loss = 0.609176, recall_at_10 = 1.0, recall_at_2 = 0.327435064935.\n",
      "INFO:tensorflow:Results after 780 steps (5.866 sec/batch): recall_at_5 = 0.658333333333, recall_at_1 = 0.186538461538, loss = 0.639403, recall_at_10 = 1.0, recall_at_2 = 0.326362179487.\n",
      "INFO:tensorflow:Results after 790 steps (5.882 sec/batch): recall_at_5 = 0.658069620253, recall_at_1 = 0.185917721519, loss = 0.6229, recall_at_10 = 1.0, recall_at_2 = 0.325870253165.\n",
      "INFO:tensorflow:Results after 800 steps (6.082 sec/batch): recall_at_5 = 0.65828125, recall_at_1 = 0.185546875, loss = 0.679868, recall_at_10 = 1.0, recall_at_2 = 0.32625.\n",
      "INFO:tensorflow:Results after 810 steps (6.005 sec/batch): recall_at_5 = 0.657638888889, recall_at_1 = 0.185262345679, loss = 0.638126, recall_at_10 = 1.0, recall_at_2 = 0.325771604938.\n",
      "INFO:tensorflow:Results after 820 steps (5.849 sec/batch): recall_at_5 = 0.658155487805, recall_at_1 = 0.184908536585, loss = 0.639577, recall_at_10 = 1.0, recall_at_2 = 0.325990853659.\n",
      "INFO:tensorflow:Results after 830 steps (5.946 sec/batch): recall_at_5 = 0.658057228916, recall_at_1 = 0.184713855422, loss = 0.62322, recall_at_10 = 1.0, recall_at_2 = 0.326204819277.\n",
      "INFO:tensorflow:Results after 840 steps (5.962 sec/batch): recall_at_5 = 0.657886904762, recall_at_1 = 0.184077380952, loss = 0.624463, recall_at_10 = 1.0, recall_at_2 = 0.325892857143.\n",
      "INFO:tensorflow:Results after 850 steps (5.960 sec/batch): recall_at_5 = 0.657132352941, recall_at_1 = 0.183970588235, loss = 0.623302, recall_at_10 = 1.0, recall_at_2 = 0.325955882353.\n",
      "INFO:tensorflow:Results after 860 steps (6.194 sec/batch): recall_at_5 = 0.657558139535, recall_at_1 = 0.184156976744, loss = 0.632821, recall_at_10 = 1.0, recall_at_2 = 0.326308139535.\n",
      "INFO:tensorflow:Results after 870 steps (5.965 sec/batch): recall_at_5 = 0.658045977011, recall_at_1 = 0.184267241379, loss = 0.636682, recall_at_10 = 1.0, recall_at_2 = 0.326293103448.\n",
      "INFO:tensorflow:Results after 880 steps (6.638 sec/batch): recall_at_5 = 0.658167613636, recall_at_1 = 0.184019886364, loss = 0.642143, recall_at_10 = 1.0, recall_at_2 = 0.325710227273.\n",
      "INFO:tensorflow:Results after 890 steps (5.994 sec/batch): recall_at_5 = 0.658216292135, recall_at_1 = 0.184129213483, loss = 0.616904, recall_at_10 = 1.0, recall_at_2 = 0.326123595506.\n",
      "INFO:tensorflow:Results after 900 steps (6.062 sec/batch): recall_at_5 = 0.658819444444, recall_at_1 = 0.184236111111, loss = 0.629689, recall_at_10 = 1.0, recall_at_2 = 0.326319444444.\n",
      "INFO:tensorflow:Results after 910 steps (5.894 sec/batch): recall_at_5 = 0.658516483516, recall_at_1 = 0.184203296703, loss = 0.633549, recall_at_10 = 1.0, recall_at_2 = 0.326510989011.\n",
      "INFO:tensorflow:Results after 920 steps (5.841 sec/batch): recall_at_5 = 0.658627717391, recall_at_1 = 0.183899456522, loss = 0.590481, recall_at_10 = 1.0, recall_at_2 = 0.326222826087.\n",
      "INFO:tensorflow:Results after 930 steps (5.849 sec/batch): recall_at_5 = 0.658870967742, recall_at_1 = 0.18373655914, loss = 0.655788, recall_at_10 = 1.0, recall_at_2 = 0.326209677419.\n",
      "INFO:tensorflow:Results after 940 steps (5.868 sec/batch): recall_at_5 = 0.657978723404, recall_at_1 = 0.182912234043, loss = 0.627038, recall_at_10 = 1.0, recall_at_2 = 0.325731382979.\n",
      "INFO:tensorflow:Results after 950 steps (5.859 sec/batch): recall_at_5 = 0.658289473684, recall_at_1 = 0.183223684211, loss = 0.628101, recall_at_10 = 1.0, recall_at_2 = 0.326118421053.\n",
      "INFO:tensorflow:Results after 960 steps (5.837 sec/batch): recall_at_5 = 0.658072916667, recall_at_1 = 0.183203125, loss = 0.625693, recall_at_10 = 1.0, recall_at_2 = 0.325716145833.\n",
      "INFO:tensorflow:Results after 970 steps (5.866 sec/batch): recall_at_5 = 0.658827319588, recall_at_1 = 0.183634020619, loss = 0.601591, recall_at_10 = 1.0, recall_at_2 = 0.326288659794.\n",
      "INFO:tensorflow:Results after 980 steps (5.832 sec/batch): recall_at_5 = 0.658354591837, recall_at_1 = 0.183418367347, loss = 0.641355, recall_at_10 = 1.0, recall_at_2 = 0.326084183673.\n",
      "INFO:tensorflow:Results after 990 steps (5.829 sec/batch): recall_at_5 = 0.657828282828, recall_at_1 = 0.183207070707, loss = 0.617134, recall_at_10 = 1.0, recall_at_2 = 0.325505050505.\n",
      "INFO:tensorflow:Results after 1000 steps (5.920 sec/batch): recall_at_5 = 0.65775, recall_at_1 = 0.1834375, loss = 0.594127, recall_at_10 = 1.0, recall_at_2 = 0.3258125.\n",
      "INFO:tensorflow:Results after 1010 steps (7.160 sec/batch): recall_at_5 = 0.658168316832, recall_at_1 = 0.183415841584, loss = 0.637824, recall_at_10 = 1.0, recall_at_2 = 0.325433168317.\n",
      "INFO:tensorflow:Results after 1020 steps (5.858 sec/batch): recall_at_5 = 0.658026960784, recall_at_1 = 0.183088235294, loss = 0.629072, recall_at_10 = 1.0, recall_at_2 = 0.325306372549.\n",
      "INFO:tensorflow:Results after 1030 steps (5.899 sec/batch): recall_at_5 = 0.65807038835, recall_at_1 = 0.183131067961, loss = 0.615921, recall_at_10 = 1.0, recall_at_2 = 0.325485436893.\n",
      "INFO:tensorflow:Results after 1040 steps (6.097 sec/batch): recall_at_5 = 0.658353365385, recall_at_1 = 0.183533653846, loss = 0.6105, recall_at_10 = 1.0, recall_at_2 = 0.326141826923.\n",
      "INFO:tensorflow:Results after 1050 steps (6.117 sec/batch): recall_at_5 = 0.658273809524, recall_at_1 = 0.183988095238, loss = 0.618959, recall_at_10 = 1.0, recall_at_2 = 0.326428571429.\n",
      "INFO:tensorflow:Results after 1060 steps (6.526 sec/batch): recall_at_5 = 0.658313679245, recall_at_1 = 0.183962264151, loss = 0.609309, recall_at_10 = 1.0, recall_at_2 = 0.326238207547.\n",
      "INFO:tensorflow:Results after 1070 steps (6.319 sec/batch): recall_at_5 = 0.658644859813, recall_at_1 = 0.183995327103, loss = 0.608195, recall_at_10 = 1.0, recall_at_2 = 0.326051401869.\n",
      "INFO:tensorflow:Results after 1080 steps (6.024 sec/batch): recall_at_5 = 0.658564814815, recall_at_1 = 0.183796296296, loss = 0.582085, recall_at_10 = 1.0, recall_at_2 = 0.325752314815.\n",
      "INFO:tensorflow:Results after 1090 steps (6.487 sec/batch): recall_at_5 = 0.658600917431, recall_at_1 = 0.18371559633, loss = 0.649001, recall_at_10 = 1.0, recall_at_2 = 0.325974770642.\n",
      "INFO:tensorflow:Results after 1100 steps (6.241 sec/batch): recall_at_5 = 0.658238636364, recall_at_1 = 0.18375, loss = 0.644141, recall_at_10 = 1.0, recall_at_2 = 0.326193181818.\n",
      "INFO:tensorflow:Results after 1110 steps (6.375 sec/batch): recall_at_5 = 0.658220720721, recall_at_1 = 0.183333333333, loss = 0.669644, recall_at_10 = 1.0, recall_at_2 = 0.326013513514.\n",
      "INFO:tensorflow:Input queue is exhausted.\n",
      "INFO:tensorflow:Step 2001: mean_loss:0 = 0.661926\n",
      "INFO:tensorflow:training step 2100, loss = 0.66256 (7.887 sec/batch).\n",
      "INFO:tensorflow:Step 2101: mean_loss:0 = 0.701638\n",
      "INFO:tensorflow:training step 2200, loss = 0.65642 (6.695 sec/batch).\n",
      "INFO:tensorflow:Step 2201: mean_loss:0 = 0.671128\n",
      "INFO:tensorflow:training step 2300, loss = 0.70468 (7.005 sec/batch).\n",
      "INFO:tensorflow:Step 2301: mean_loss:0 = 0.642954\n",
      "INFO:tensorflow:training step 2400, loss = 0.65608 (6.775 sec/batch).\n",
      "INFO:tensorflow:Step 2401: mean_loss:0 = 0.655213\n",
      "INFO:tensorflow:training step 2500, loss = 0.62550 (7.173 sec/batch).\n",
      "INFO:tensorflow:Step 2501: mean_loss:0 = 0.648087\n",
      "INFO:tensorflow:training step 2600, loss = 0.65029 (8.084 sec/batch).\n",
      "INFO:tensorflow:Step 2601: mean_loss:0 = 0.680593\n",
      "INFO:tensorflow:training step 2700, loss = 0.59505 (7.097 sec/batch).\n",
      "INFO:tensorflow:Step 2701: mean_loss:0 = 0.604551\n",
      "INFO:tensorflow:training step 2800, loss = 0.63642 (7.405 sec/batch).\n",
      "INFO:tensorflow:Step 2801: mean_loss:0 = 0.666476\n",
      "INFO:tensorflow:training step 2900, loss = 0.69641 (7.112 sec/batch).\n",
      "INFO:tensorflow:Step 2901: mean_loss:0 = 0.663109\n",
      "INFO:tensorflow:training step 3000, loss = 0.63937 (7.498 sec/batch).\n",
      "INFO:tensorflow:Step 3001: mean_loss:0 = 0.622664\n",
      "INFO:tensorflow:training step 3100, loss = 0.64317 (6.710 sec/batch).\n",
      "INFO:tensorflow:Step 3101: mean_loss:0 = 0.683141\n",
      "INFO:tensorflow:training step 3200, loss = 0.63859 (6.966 sec/batch).\n",
      "INFO:tensorflow:Step 3201: mean_loss:0 = 0.611908\n",
      "INFO:tensorflow:training step 3300, loss = 0.60219 (6.997 sec/batch).\n",
      "INFO:tensorflow:Step 3301: mean_loss:0 = 0.622774\n",
      "INFO:tensorflow:training step 3400, loss = 0.60125 (6.792 sec/batch).\n",
      "INFO:tensorflow:Step 3401: mean_loss:0 = 0.598064\n",
      "INFO:tensorflow:training step 3500, loss = 0.59860 (7.479 sec/batch).\n",
      "INFO:tensorflow:Step 3501: mean_loss:0 = 0.631829\n",
      "INFO:tensorflow:training step 3600, loss = 0.62171 (7.544 sec/batch).\n",
      "INFO:tensorflow:Step 3601: mean_loss:0 = 0.559472\n",
      "INFO:tensorflow:training step 3700, loss = 0.54436 (7.061 sec/batch).\n",
      "INFO:tensorflow:Step 3701: mean_loss:0 = 0.57814\n",
      "INFO:tensorflow:training step 3800, loss = 0.64792 (6.818 sec/batch).\n",
      "INFO:tensorflow:Step 3801: mean_loss:0 = 0.549824\n",
      "INFO:tensorflow:training step 3900, loss = 0.64736 (7.928 sec/batch).\n",
      "INFO:tensorflow:Step 3901: mean_loss:0 = 0.616529\n",
      "INFO:tensorflow:training step 4000, loss = 0.65191 (7.321 sec/batch).\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Restored model from /root/work/chatbot-retrieval/runs/1468168955/model.ckpt-3976-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 3976.\n",
      "INFO:tensorflow:Results after 10 steps (6.120 sec/batch): recall_at_5 = 0.7375, recall_at_1 = 0.2625, loss = 0.716479, recall_at_10 = 1.0, recall_at_2 = 0.4625.\n",
      "INFO:tensorflow:Results after 20 steps (6.052 sec/batch): recall_at_5 = 0.7375, recall_at_1 = 0.240625, loss = 0.68399, recall_at_10 = 1.0, recall_at_2 = 0.434375.\n",
      "INFO:tensorflow:Results after 30 steps (6.399 sec/batch): recall_at_5 = 0.75625, recall_at_1 = 0.258333333333, loss = 0.715734, recall_at_10 = 1.0, recall_at_2 = 0.452083333333.\n",
      "INFO:tensorflow:Results after 40 steps (6.404 sec/batch): recall_at_5 = 0.7296875, recall_at_1 = 0.24375, loss = 0.785933, recall_at_10 = 1.0, recall_at_2 = 0.4296875.\n",
      "INFO:tensorflow:Results after 50 steps (6.274 sec/batch): recall_at_5 = 0.7475, recall_at_1 = 0.24, loss = 0.649149, recall_at_10 = 1.0, recall_at_2 = 0.43375.\n",
      "INFO:tensorflow:Results after 60 steps (6.397 sec/batch): recall_at_5 = 0.755208333333, recall_at_1 = 0.246875, loss = 0.733193, recall_at_10 = 1.0, recall_at_2 = 0.436458333333.\n",
      "INFO:tensorflow:Results after 70 steps (6.128 sec/batch): recall_at_5 = 0.754464285714, recall_at_1 = 0.249107142857, loss = 0.781718, recall_at_10 = 1.0, recall_at_2 = 0.435714285714.\n",
      "INFO:tensorflow:Results after 80 steps (6.721 sec/batch): recall_at_5 = 0.75078125, recall_at_1 = 0.2484375, loss = 0.68547, recall_at_10 = 1.0, recall_at_2 = 0.4328125.\n",
      "INFO:tensorflow:Results after 90 steps (6.038 sec/batch): recall_at_5 = 0.751388888889, recall_at_1 = 0.251388888889, loss = 0.703502, recall_at_10 = 1.0, recall_at_2 = 0.434027777778.\n",
      "INFO:tensorflow:Results after 100 steps (5.917 sec/batch): recall_at_5 = 0.74875, recall_at_1 = 0.255625, loss = 0.741686, recall_at_10 = 1.0, recall_at_2 = 0.43875.\n",
      "INFO:tensorflow:Results after 110 steps (5.933 sec/batch): recall_at_5 = 0.744886363636, recall_at_1 = 0.252840909091, loss = 0.701742, recall_at_10 = 1.0, recall_at_2 = 0.434659090909.\n",
      "INFO:tensorflow:Results after 120 steps (6.140 sec/batch): recall_at_5 = 0.744791666667, recall_at_1 = 0.25625, loss = 0.764717, recall_at_10 = 1.0, recall_at_2 = 0.435416666667.\n",
      "INFO:tensorflow:Results after 130 steps (6.109 sec/batch): recall_at_5 = 0.74375, recall_at_1 = 0.252403846154, loss = 0.722815, recall_at_10 = 1.0, recall_at_2 = 0.429807692308.\n",
      "INFO:tensorflow:Results after 140 steps (6.492 sec/batch): recall_at_5 = 0.737946428571, recall_at_1 = 0.250892857143, loss = 0.746028, recall_at_10 = 1.0, recall_at_2 = 0.426339285714.\n",
      "INFO:tensorflow:Results after 150 steps (6.635 sec/batch): recall_at_5 = 0.738333333333, recall_at_1 = 0.251666666667, loss = 0.710732, recall_at_10 = 1.0, recall_at_2 = 0.425833333333.\n",
      "INFO:tensorflow:Results after 160 steps (5.888 sec/batch): recall_at_5 = 0.737109375, recall_at_1 = 0.2515625, loss = 0.75306, recall_at_10 = 1.0, recall_at_2 = 0.425.\n",
      "INFO:tensorflow:Results after 170 steps (6.286 sec/batch): recall_at_5 = 0.735661764706, recall_at_1 = 0.248897058824, loss = 0.71111, recall_at_10 = 1.0, recall_at_2 = 0.420220588235.\n",
      "INFO:tensorflow:Results after 180 steps (6.695 sec/batch): recall_at_5 = 0.735069444444, recall_at_1 = 0.246180555556, loss = 0.705178, recall_at_10 = 1.0, recall_at_2 = 0.417708333333.\n",
      "INFO:tensorflow:Results after 190 steps (8.121 sec/batch): recall_at_5 = 0.733881578947, recall_at_1 = 0.244736842105, loss = 0.722186, recall_at_10 = 1.0, recall_at_2 = 0.415460526316.\n",
      "INFO:tensorflow:Results after 200 steps (9.189 sec/batch): recall_at_5 = 0.7353125, recall_at_1 = 0.2459375, loss = 0.692393, recall_at_10 = 1.0, recall_at_2 = 0.416875.\n",
      "INFO:tensorflow:Results after 210 steps (6.126 sec/batch): recall_at_5 = 0.734226190476, recall_at_1 = 0.245535714286, loss = 0.735963, recall_at_10 = 1.0, recall_at_2 = 0.416666666667.\n",
      "INFO:tensorflow:Results after 220 steps (5.965 sec/batch): recall_at_5 = 0.734943181818, recall_at_1 = 0.246022727273, loss = 0.72392, recall_at_10 = 1.0, recall_at_2 = 0.417613636364.\n",
      "INFO:tensorflow:Results after 230 steps (6.014 sec/batch): recall_at_5 = 0.738043478261, recall_at_1 = 0.246467391304, loss = 0.703798, recall_at_10 = 1.0, recall_at_2 = 0.41875.\n",
      "INFO:tensorflow:Results after 240 steps (5.967 sec/batch): recall_at_5 = 0.73828125, recall_at_1 = 0.247395833333, loss = 0.703847, recall_at_10 = 1.0, recall_at_2 = 0.419010416667.\n",
      "INFO:tensorflow:Results after 250 steps (6.023 sec/batch): recall_at_5 = 0.737, recall_at_1 = 0.24925, loss = 0.658761, recall_at_10 = 1.0, recall_at_2 = 0.41925.\n",
      "INFO:tensorflow:Results after 260 steps (6.013 sec/batch): recall_at_5 = 0.737740384615, recall_at_1 = 0.25, loss = 0.780476, recall_at_10 = 1.0, recall_at_2 = 0.421153846154.\n",
      "INFO:tensorflow:Results after 270 steps (5.968 sec/batch): recall_at_5 = 0.738888888889, recall_at_1 = 0.254166666667, loss = 0.686487, recall_at_10 = 1.0, recall_at_2 = 0.425231481481.\n",
      "INFO:tensorflow:Results after 280 steps (6.044 sec/batch): recall_at_5 = 0.739285714286, recall_at_1 = 0.255803571429, loss = 0.746991, recall_at_10 = 1.0, recall_at_2 = 0.426339285714.\n",
      "INFO:tensorflow:Results after 290 steps (6.572 sec/batch): recall_at_5 = 0.739870689655, recall_at_1 = 0.256681034483, loss = 0.646459, recall_at_10 = 1.0, recall_at_2 = 0.425862068966.\n",
      "INFO:tensorflow:Results after 300 steps (5.923 sec/batch): recall_at_5 = 0.73875, recall_at_1 = 0.255, loss = 0.720108, recall_at_10 = 1.0, recall_at_2 = 0.425.\n",
      "INFO:tensorflow:Results after 310 steps (5.948 sec/batch): recall_at_5 = 0.737903225806, recall_at_1 = 0.253427419355, loss = 0.717767, recall_at_10 = 1.0, recall_at_2 = 0.423790322581.\n",
      "INFO:tensorflow:Results after 320 steps (5.902 sec/batch): recall_at_5 = 0.7392578125, recall_at_1 = 0.2541015625, loss = 0.726186, recall_at_10 = 1.0, recall_at_2 = 0.426171875.\n",
      "INFO:tensorflow:Results after 330 steps (5.829 sec/batch): recall_at_5 = 0.74053030303, recall_at_1 = 0.252840909091, loss = 0.667954, recall_at_10 = 1.0, recall_at_2 = 0.424810606061.\n",
      "INFO:tensorflow:Results after 340 steps (6.161 sec/batch): recall_at_5 = 0.740257352941, recall_at_1 = 0.252389705882, loss = 0.732392, recall_at_10 = 1.0, recall_at_2 = 0.424816176471.\n",
      "INFO:tensorflow:Results after 350 steps (8.610 sec/batch): recall_at_5 = 0.741785714286, recall_at_1 = 0.252142857143, loss = 0.749836, recall_at_10 = 1.0, recall_at_2 = 0.424642857143.\n",
      "INFO:tensorflow:Results after 360 steps (7.280 sec/batch): recall_at_5 = 0.741145833333, recall_at_1 = 0.250868055556, loss = 0.755973, recall_at_10 = 1.0, recall_at_2 = 0.4234375.\n",
      "INFO:tensorflow:Results after 370 steps (6.313 sec/batch): recall_at_5 = 0.739358108108, recall_at_1 = 0.249662162162, loss = 0.721439, recall_at_10 = 1.0, recall_at_2 = 0.423141891892.\n",
      "INFO:tensorflow:Results after 380 steps (7.437 sec/batch): recall_at_5 = 0.738486842105, recall_at_1 = 0.250328947368, loss = 0.684876, recall_at_10 = 1.0, recall_at_2 = 0.422861842105.\n",
      "INFO:tensorflow:Results after 390 steps (7.369 sec/batch): recall_at_5 = 0.738942307692, recall_at_1 = 0.249519230769, loss = 0.754911, recall_at_10 = 1.0, recall_at_2 = 0.421634615385.\n",
      "INFO:tensorflow:Results after 400 steps (6.194 sec/batch): recall_at_5 = 0.7378125, recall_at_1 = 0.24890625, loss = 0.713548, recall_at_10 = 1.0, recall_at_2 = 0.42078125.\n",
      "INFO:tensorflow:Results after 410 steps (7.716 sec/batch): recall_at_5 = 0.738109756098, recall_at_1 = 0.249237804878, loss = 0.729828, recall_at_10 = 1.0, recall_at_2 = 0.420731707317.\n",
      "INFO:tensorflow:Results after 420 steps (7.871 sec/batch): recall_at_5 = 0.737053571429, recall_at_1 = 0.248214285714, loss = 0.754275, recall_at_10 = 1.0, recall_at_2 = 0.420982142857.\n",
      "INFO:tensorflow:Results after 430 steps (6.080 sec/batch): recall_at_5 = 0.735465116279, recall_at_1 = 0.248255813953, loss = 0.729674, recall_at_10 = 1.0, recall_at_2 = 0.420494186047.\n",
      "INFO:tensorflow:Results after 440 steps (7.564 sec/batch): recall_at_5 = 0.735511363636, recall_at_1 = 0.247017045455, loss = 0.704239, recall_at_10 = 1.0, recall_at_2 = 0.418607954545.\n",
      "INFO:tensorflow:Results after 450 steps (7.787 sec/batch): recall_at_5 = 0.736527777778, recall_at_1 = 0.245555555556, loss = 0.758283, recall_at_10 = 1.0, recall_at_2 = 0.418611111111.\n",
      "INFO:tensorflow:Results after 460 steps (6.366 sec/batch): recall_at_5 = 0.736820652174, recall_at_1 = 0.245516304348, loss = 0.777811, recall_at_10 = 1.0, recall_at_2 = 0.418342391304.\n",
      "INFO:tensorflow:Results after 470 steps (8.114 sec/batch): recall_at_5 = 0.737367021277, recall_at_1 = 0.246010638298, loss = 0.754962, recall_at_10 = 1.0, recall_at_2 = 0.419414893617.\n",
      "INFO:tensorflow:Results after 480 steps (7.745 sec/batch): recall_at_5 = 0.737369791667, recall_at_1 = 0.246614583333, loss = 0.72792, recall_at_10 = 1.0, recall_at_2 = 0.419270833333.\n",
      "INFO:tensorflow:Results after 490 steps (6.287 sec/batch): recall_at_5 = 0.736607142857, recall_at_1 = 0.246556122449, loss = 0.742773, recall_at_10 = 1.0, recall_at_2 = 0.41887755102.\n",
      "INFO:tensorflow:Results after 500 steps (7.745 sec/batch): recall_at_5 = 0.737, recall_at_1 = 0.2465, loss = 0.676513, recall_at_10 = 1.0, recall_at_2 = 0.418875.\n",
      "INFO:tensorflow:Results after 510 steps (7.944 sec/batch): recall_at_5 = 0.737745098039, recall_at_1 = 0.245588235294, loss = 0.738877, recall_at_10 = 1.0, recall_at_2 = 0.419240196078.\n",
      "INFO:tensorflow:Results after 520 steps (6.081 sec/batch): recall_at_5 = 0.737740384615, recall_at_1 = 0.246754807692, loss = 0.699641, recall_at_10 = 1.0, recall_at_2 = 0.419711538462.\n",
      "INFO:tensorflow:Results after 530 steps (8.995 sec/batch): recall_at_5 = 0.736556603774, recall_at_1 = 0.245636792453, loss = 0.755001, recall_at_10 = 1.0, recall_at_2 = 0.419103773585.\n",
      "INFO:tensorflow:Results after 540 steps (7.520 sec/batch): recall_at_5 = 0.736111111111, recall_at_1 = 0.245833333333, loss = 0.720561, recall_at_10 = 1.0, recall_at_2 = 0.418518518519.\n",
      "INFO:tensorflow:Results after 550 steps (6.156 sec/batch): recall_at_5 = 0.735909090909, recall_at_1 = 0.244886363636, loss = 0.733257, recall_at_10 = 1.0, recall_at_2 = 0.417045454545.\n",
      "INFO:tensorflow:Results after 560 steps (8.263 sec/batch): recall_at_5 = 0.737053571429, recall_at_1 = 0.243973214286, loss = 0.809115, recall_at_10 = 1.0, recall_at_2 = 0.417522321429.\n",
      "INFO:tensorflow:Results after 570 steps (6.419 sec/batch): recall_at_5 = 0.737280701754, recall_at_1 = 0.245285087719, loss = 0.741623, recall_at_10 = 1.0, recall_at_2 = 0.41798245614.\n",
      "INFO:tensorflow:Results after 580 steps (6.439 sec/batch): recall_at_5 = 0.737284482759, recall_at_1 = 0.244827586207, loss = 0.725546, recall_at_10 = 1.0, recall_at_2 = 0.417564655172.\n",
      "INFO:tensorflow:Results after 590 steps (6.171 sec/batch): recall_at_5 = 0.735911016949, recall_at_1 = 0.24343220339, loss = 0.76401, recall_at_10 = 1.0, recall_at_2 = 0.416843220339.\n",
      "INFO:tensorflow:Results after 600 steps (6.014 sec/batch): recall_at_5 = 0.73625, recall_at_1 = 0.2434375, loss = 0.755781, recall_at_10 = 1.0, recall_at_2 = 0.417291666667.\n",
      "INFO:tensorflow:Results after 610 steps (6.120 sec/batch): recall_at_5 = 0.736885245902, recall_at_1 = 0.244364754098, loss = 0.693742, recall_at_10 = 1.0, recall_at_2 = 0.417418032787.\n",
      "INFO:tensorflow:Results after 620 steps (6.026 sec/batch): recall_at_5 = 0.737399193548, recall_at_1 = 0.245564516129, loss = 0.655251, recall_at_10 = 1.0, recall_at_2 = 0.41875.\n",
      "INFO:tensorflow:Results after 630 steps (7.358 sec/batch): recall_at_5 = 0.738293650794, recall_at_1 = 0.245833333333, loss = 0.731508, recall_at_10 = 1.0, recall_at_2 = 0.419047619048.\n",
      "INFO:tensorflow:Results after 640 steps (6.078 sec/batch): recall_at_5 = 0.7380859375, recall_at_1 = 0.24609375, loss = 0.685301, recall_at_10 = 1.0, recall_at_2 = 0.41923828125.\n",
      "INFO:tensorflow:Results after 650 steps (6.152 sec/batch): recall_at_5 = 0.737596153846, recall_at_1 = 0.246442307692, loss = 0.727155, recall_at_10 = 1.0, recall_at_2 = 0.419230769231.\n",
      "INFO:tensorflow:Results after 660 steps (6.177 sec/batch): recall_at_5 = 0.737689393939, recall_at_1 = 0.246212121212, loss = 0.758682, recall_at_10 = 1.0, recall_at_2 = 0.419223484848.\n",
      "INFO:tensorflow:Results after 670 steps (6.077 sec/batch): recall_at_5 = 0.738059701493, recall_at_1 = 0.246175373134, loss = 0.704428, recall_at_10 = 1.0, recall_at_2 = 0.418376865672.\n",
      "INFO:tensorflow:Results after 680 steps (6.021 sec/batch): recall_at_5 = 0.737959558824, recall_at_1 = 0.246231617647, loss = 0.730969, recall_at_10 = 1.0, recall_at_2 = 0.418474264706.\n",
      "INFO:tensorflow:Results after 690 steps (6.058 sec/batch): recall_at_5 = 0.738586956522, recall_at_1 = 0.246557971014, loss = 0.807347, recall_at_10 = 1.0, recall_at_2 = 0.418297101449.\n",
      "INFO:tensorflow:Results after 700 steps (5.988 sec/batch): recall_at_5 = 0.737946428571, recall_at_1 = 0.246428571429, loss = 0.690013, recall_at_10 = 1.0, recall_at_2 = 0.418035714286.\n",
      "INFO:tensorflow:Results after 710 steps (6.061 sec/batch): recall_at_5 = 0.738204225352, recall_at_1 = 0.246302816901, loss = 0.731323, recall_at_10 = 1.0, recall_at_2 = 0.418133802817.\n",
      "INFO:tensorflow:Results after 720 steps (6.179 sec/batch): recall_at_5 = 0.738888888889, recall_at_1 = 0.246961805556, loss = 0.787362, recall_at_10 = 1.0, recall_at_2 = 0.418836805556.\n",
      "INFO:tensorflow:Results after 730 steps (5.953 sec/batch): recall_at_5 = 0.738955479452, recall_at_1 = 0.246746575342, loss = 0.717351, recall_at_10 = 1.0, recall_at_2 = 0.418321917808.\n",
      "INFO:tensorflow:Results after 740 steps (5.953 sec/batch): recall_at_5 = 0.738682432432, recall_at_1 = 0.246368243243, loss = 0.757149, recall_at_10 = 1.0, recall_at_2 = 0.417736486486.\n",
      "INFO:tensorflow:Results after 750 steps (6.035 sec/batch): recall_at_5 = 0.737916666667, recall_at_1 = 0.24625, loss = 0.668814, recall_at_10 = 1.0, recall_at_2 = 0.416833333333.\n",
      "INFO:tensorflow:Results after 760 steps (6.016 sec/batch): recall_at_5 = 0.738240131579, recall_at_1 = 0.246546052632, loss = 0.705414, recall_at_10 = 1.0, recall_at_2 = 0.417023026316.\n",
      "INFO:tensorflow:Results after 770 steps (6.270 sec/batch): recall_at_5 = 0.738311688312, recall_at_1 = 0.246590909091, loss = 0.785774, recall_at_10 = 1.0, recall_at_2 = 0.417045454545.\n",
      "INFO:tensorflow:Results after 780 steps (6.296 sec/batch): recall_at_5 = 0.738381410256, recall_at_1 = 0.246474358974, loss = 0.724272, recall_at_10 = 1.0, recall_at_2 = 0.417227564103.\n",
      "INFO:tensorflow:Results after 790 steps (5.968 sec/batch): recall_at_5 = 0.737737341772, recall_at_1 = 0.246202531646, loss = 0.709323, recall_at_10 = 1.0, recall_at_2 = 0.416851265823.\n",
      "INFO:tensorflow:Results after 800 steps (6.130 sec/batch): recall_at_5 = 0.736875, recall_at_1 = 0.245859375, loss = 0.745828, recall_at_10 = 1.0, recall_at_2 = 0.41609375.\n",
      "INFO:tensorflow:Results after 810 steps (6.184 sec/batch): recall_at_5 = 0.736882716049, recall_at_1 = 0.245987654321, loss = 0.724904, recall_at_10 = 1.0, recall_at_2 = 0.416589506173.\n",
      "INFO:tensorflow:Results after 820 steps (6.180 sec/batch): recall_at_5 = 0.736432926829, recall_at_1 = 0.246265243902, loss = 0.715628, recall_at_10 = 1.0, recall_at_2 = 0.417073170732.\n",
      "INFO:tensorflow:Results after 830 steps (6.441 sec/batch): recall_at_5 = 0.736144578313, recall_at_1 = 0.246686746988, loss = 0.733368, recall_at_10 = 1.0, recall_at_2 = 0.417018072289.\n",
      "INFO:tensorflow:Results after 840 steps (6.144 sec/batch): recall_at_5 = 0.736532738095, recall_at_1 = 0.246205357143, loss = 0.770563, recall_at_10 = 1.0, recall_at_2 = 0.416369047619.\n",
      "INFO:tensorflow:Results after 850 steps (6.348 sec/batch): recall_at_5 = 0.736176470588, recall_at_1 = 0.245441176471, loss = 0.732286, recall_at_10 = 1.0, recall_at_2 = 0.416029411765.\n",
      "INFO:tensorflow:Results after 860 steps (6.277 sec/batch): recall_at_5 = 0.736191860465, recall_at_1 = 0.246220930233, loss = 0.760062, recall_at_10 = 1.0, recall_at_2 = 0.41664244186.\n",
      "INFO:tensorflow:Results after 870 steps (6.492 sec/batch): recall_at_5 = 0.735632183908, recall_at_1 = 0.246120689655, loss = 0.779488, recall_at_10 = 1.0, recall_at_2 = 0.41558908046.\n",
      "INFO:tensorflow:Results after 880 steps (6.072 sec/batch): recall_at_5 = 0.736363636364, recall_at_1 = 0.246590909091, loss = 0.746205, recall_at_10 = 1.0, recall_at_2 = 0.416193181818.\n",
      "INFO:tensorflow:Results after 890 steps (6.284 sec/batch): recall_at_5 = 0.735463483146, recall_at_1 = 0.245575842697, loss = 0.729518, recall_at_10 = 1.0, recall_at_2 = 0.414887640449.\n",
      "INFO:tensorflow:Results after 900 steps (6.886 sec/batch): recall_at_5 = 0.735833333333, recall_at_1 = 0.245347222222, loss = 0.73957, recall_at_10 = 1.0, recall_at_2 = 0.414930555556.\n",
      "INFO:tensorflow:Results after 910 steps (5.990 sec/batch): recall_at_5 = 0.735851648352, recall_at_1 = 0.244848901099, loss = 0.661191, recall_at_10 = 1.0, recall_at_2 = 0.415041208791.\n",
      "INFO:tensorflow:Results after 920 steps (6.118 sec/batch): recall_at_5 = 0.736005434783, recall_at_1 = 0.244633152174, loss = 0.65719, recall_at_10 = 1.0, recall_at_2 = 0.414877717391.\n",
      "INFO:tensorflow:Results after 930 steps (6.219 sec/batch): recall_at_5 = 0.735954301075, recall_at_1 = 0.244489247312, loss = 0.771334, recall_at_10 = 1.0, recall_at_2 = 0.41438172043.\n",
      "INFO:tensorflow:Results after 940 steps (5.966 sec/batch): recall_at_5 = 0.735305851064, recall_at_1 = 0.243882978723, loss = 0.816273, recall_at_10 = 1.0, recall_at_2 = 0.413896276596.\n",
      "INFO:tensorflow:Results after 950 steps (6.088 sec/batch): recall_at_5 = 0.735065789474, recall_at_1 = 0.244078947368, loss = 0.652962, recall_at_10 = 1.0, recall_at_2 = 0.413618421053.\n",
      "INFO:tensorflow:Results after 960 steps (6.085 sec/batch): recall_at_5 = 0.73515625, recall_at_1 = 0.244140625, loss = 0.788194, recall_at_10 = 1.0, recall_at_2 = 0.413216145833.\n",
      "INFO:tensorflow:Results after 970 steps (6.064 sec/batch): recall_at_5 = 0.735824742268, recall_at_1 = 0.244201030928, loss = 0.706118, recall_at_10 = 1.0, recall_at_2 = 0.413788659794.\n",
      "INFO:tensorflow:Results after 980 steps (7.318 sec/batch): recall_at_5 = 0.735140306122, recall_at_1 = 0.24368622449, loss = 0.689039, recall_at_10 = 1.0, recall_at_2 = 0.413711734694.\n",
      "INFO:tensorflow:Results after 990 steps (6.033 sec/batch): recall_at_5 = 0.73529040404, recall_at_1 = 0.243686868687, loss = 0.739859, recall_at_10 = 1.0, recall_at_2 = 0.413825757576.\n",
      "INFO:tensorflow:Results after 1000 steps (6.846 sec/batch): recall_at_5 = 0.735625, recall_at_1 = 0.243625, loss = 0.740701, recall_at_10 = 1.0, recall_at_2 = 0.414125.\n",
      "INFO:tensorflow:Results after 1010 steps (6.047 sec/batch): recall_at_5 = 0.734962871287, recall_at_1 = 0.243935643564, loss = 0.736299, recall_at_10 = 1.0, recall_at_2 = 0.414170792079.\n",
      "INFO:tensorflow:Results after 1020 steps (6.429 sec/batch): recall_at_5 = 0.734987745098, recall_at_1 = 0.24375, loss = 0.74288, recall_at_10 = 1.0, recall_at_2 = 0.414276960784.\n",
      "INFO:tensorflow:Results after 1030 steps (6.084 sec/batch): recall_at_5 = 0.735254854369, recall_at_1 = 0.24411407767, loss = 0.767729, recall_at_10 = 1.0, recall_at_2 = 0.414623786408.\n",
      "INFO:tensorflow:Results after 1040 steps (6.263 sec/batch): recall_at_5 = 0.736057692308, recall_at_1 = 0.2453125, loss = 0.720523, recall_at_10 = 1.0, recall_at_2 = 0.415625.\n",
      "INFO:tensorflow:Results after 1050 steps (6.480 sec/batch): recall_at_5 = 0.735833333333, recall_at_1 = 0.244821428571, loss = 0.681234, recall_at_10 = 1.0, recall_at_2 = 0.41505952381.\n",
      "INFO:tensorflow:Results after 1060 steps (6.176 sec/batch): recall_at_5 = 0.735613207547, recall_at_1 = 0.244811320755, loss = 0.703753, recall_at_10 = 1.0, recall_at_2 = 0.415212264151.\n",
      "INFO:tensorflow:Results after 1070 steps (6.008 sec/batch): recall_at_5 = 0.735455607477, recall_at_1 = 0.244392523364, loss = 0.733366, recall_at_10 = 1.0, recall_at_2 = 0.414894859813.\n",
      "INFO:tensorflow:Results after 1080 steps (6.096 sec/batch): recall_at_5 = 0.735011574074, recall_at_1 = 0.244444444444, loss = 0.715261, recall_at_10 = 1.0, recall_at_2 = 0.414583333333.\n",
      "INFO:tensorflow:Results after 1090 steps (5.998 sec/batch): recall_at_5 = 0.734690366972, recall_at_1 = 0.244495412844, loss = 0.732867, recall_at_10 = 1.0, recall_at_2 = 0.414678899083.\n",
      "INFO:tensorflow:Results after 1100 steps (6.083 sec/batch): recall_at_5 = 0.735056818182, recall_at_1 = 0.244318181818, loss = 0.751736, recall_at_10 = 1.0, recall_at_2 = 0.414090909091.\n",
      "INFO:tensorflow:Results after 1110 steps (5.983 sec/batch): recall_at_5 = 0.735078828829, recall_at_1 = 0.243637387387, loss = 0.774398, recall_at_10 = 1.0, recall_at_2 = 0.413288288288.\n",
      "INFO:tensorflow:Input queue is exhausted.\n",
      "INFO:tensorflow:Step 4001: mean_loss:0 = 0.600749\n",
      "INFO:tensorflow:training step 4100, loss = 0.57995 (7.213 sec/batch).\n",
      "INFO:tensorflow:Step 4101: mean_loss:0 = 0.565472\n",
      "INFO:tensorflow:training step 4200, loss = 0.58545 (7.117 sec/batch).\n",
      "INFO:tensorflow:Step 4201: mean_loss:0 = 0.564311\n",
      "INFO:tensorflow:training step 4300, loss = 0.64401 (7.583 sec/batch).\n",
      "INFO:tensorflow:Step 4301: mean_loss:0 = 0.617198\n",
      "INFO:tensorflow:training step 4400, loss = 0.66571 (6.975 sec/batch).\n",
      "INFO:tensorflow:Step 4401: mean_loss:0 = 0.583548\n",
      "INFO:tensorflow:training step 4500, loss = 0.63563 (7.301 sec/batch).\n",
      "INFO:tensorflow:Step 4501: mean_loss:0 = 0.574147\n",
      "INFO:tensorflow:training step 4600, loss = 0.54040 (7.970 sec/batch).\n",
      "INFO:tensorflow:Step 4601: mean_loss:0 = 0.598233\n",
      "INFO:tensorflow:training step 4700, loss = 0.64436 (8.541 sec/batch).\n",
      "INFO:tensorflow:Step 4701: mean_loss:0 = 0.597794\n",
      "INFO:tensorflow:training step 4800, loss = 0.59068 (7.309 sec/batch).\n",
      "INFO:tensorflow:Step 4801: mean_loss:0 = 0.622924\n",
      "INFO:tensorflow:training step 4900, loss = 0.62428 (6.961 sec/batch).\n",
      "INFO:tensorflow:Step 4901: mean_loss:0 = 0.629002\n",
      "INFO:tensorflow:training step 5000, loss = 0.56949 (7.787 sec/batch).\n",
      "INFO:tensorflow:Step 5001: mean_loss:0 = 0.633482\n",
      "INFO:tensorflow:training step 5100, loss = 0.61082 (7.128 sec/batch).\n",
      "INFO:tensorflow:Step 5101: mean_loss:0 = 0.606965\n",
      "INFO:tensorflow:training step 5200, loss = 0.52827 (7.168 sec/batch).\n",
      "INFO:tensorflow:Step 5201: mean_loss:0 = 0.575196\n",
      "INFO:tensorflow:training step 5300, loss = 0.54211 (7.392 sec/batch).\n",
      "INFO:tensorflow:Step 5301: mean_loss:0 = 0.664567\n",
      "INFO:tensorflow:training step 5400, loss = 0.54952 (7.046 sec/batch).\n",
      "INFO:tensorflow:Step 5401: mean_loss:0 = 0.538353\n",
      "INFO:tensorflow:training step 5500, loss = 0.48090 (6.804 sec/batch).\n",
      "INFO:tensorflow:Step 5501: mean_loss:0 = 0.531324\n",
      "INFO:tensorflow:training step 5600, loss = 0.65154 (7.862 sec/batch).\n",
      "INFO:tensorflow:Step 5601: mean_loss:0 = 0.56486\n",
      "INFO:tensorflow:training step 5700, loss = 0.55214 (7.053 sec/batch).\n",
      "INFO:tensorflow:Step 5701: mean_loss:0 = 0.577287\n",
      "INFO:tensorflow:training step 5800, loss = 0.54404 (7.700 sec/batch).\n",
      "INFO:tensorflow:Step 5801: mean_loss:0 = 0.585839\n",
      "INFO:tensorflow:training step 5900, loss = 0.59169 (7.334 sec/batch).\n",
      "INFO:tensorflow:Step 5901: mean_loss:0 = 0.514933\n",
      "INFO:tensorflow:training step 6000, loss = 0.54443 (7.446 sec/batch).\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Restored model from /root/work/chatbot-retrieval/runs/1468168955/model.ckpt-5957-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 5957.\n",
      "INFO:tensorflow:Results after 10 steps (5.785 sec/batch): recall_at_5 = 0.81875, recall_at_1 = 0.35625, loss = 0.601846, recall_at_10 = 1.0, recall_at_2 = 0.5625.\n",
      "INFO:tensorflow:Results after 20 steps (6.031 sec/batch): recall_at_5 = 0.825, recall_at_1 = 0.359375, loss = 0.572687, recall_at_10 = 1.0, recall_at_2 = 0.55.\n",
      "INFO:tensorflow:Results after 30 steps (5.792 sec/batch): recall_at_5 = 0.827083333333, recall_at_1 = 0.372916666667, loss = 0.618665, recall_at_10 = 1.0, recall_at_2 = 0.55625.\n",
      "INFO:tensorflow:Results after 40 steps (5.827 sec/batch): recall_at_5 = 0.825, recall_at_1 = 0.3640625, loss = 0.567778, recall_at_10 = 1.0, recall_at_2 = 0.5390625.\n",
      "INFO:tensorflow:Results after 50 steps (6.108 sec/batch): recall_at_5 = 0.84, recall_at_1 = 0.37125, loss = 0.577079, recall_at_10 = 1.0, recall_at_2 = 0.55375.\n",
      "INFO:tensorflow:Results after 60 steps (6.135 sec/batch): recall_at_5 = 0.855208333333, recall_at_1 = 0.378125, loss = 0.595805, recall_at_10 = 1.0, recall_at_2 = 0.565625.\n",
      "INFO:tensorflow:Results after 70 steps (6.306 sec/batch): recall_at_5 = 0.851785714286, recall_at_1 = 0.376785714286, loss = 0.638566, recall_at_10 = 1.0, recall_at_2 = 0.560714285714.\n",
      "INFO:tensorflow:Results after 80 steps (6.184 sec/batch): recall_at_5 = 0.85390625, recall_at_1 = 0.3828125, loss = 0.695976, recall_at_10 = 1.0, recall_at_2 = 0.5671875.\n",
      "INFO:tensorflow:Results after 90 steps (6.140 sec/batch): recall_at_5 = 0.85, recall_at_1 = 0.382638888889, loss = 0.605088, recall_at_10 = 1.0, recall_at_2 = 0.563194444444.\n",
      "INFO:tensorflow:Results after 100 steps (5.982 sec/batch): recall_at_5 = 0.85125, recall_at_1 = 0.385625, loss = 0.61018, recall_at_10 = 1.0, recall_at_2 = 0.56875.\n",
      "INFO:tensorflow:Results after 110 steps (6.251 sec/batch): recall_at_5 = 0.847727272727, recall_at_1 = 0.384090909091, loss = 0.566594, recall_at_10 = 1.0, recall_at_2 = 0.566477272727.\n",
      "INFO:tensorflow:Results after 120 steps (6.331 sec/batch): recall_at_5 = 0.849479166667, recall_at_1 = 0.383333333333, loss = 0.631443, recall_at_10 = 1.0, recall_at_2 = 0.5671875.\n",
      "INFO:tensorflow:Results after 130 steps (6.137 sec/batch): recall_at_5 = 0.845673076923, recall_at_1 = 0.378365384615, loss = 0.619007, recall_at_10 = 1.0, recall_at_2 = 0.559134615385.\n",
      "INFO:tensorflow:Results after 140 steps (6.066 sec/batch): recall_at_5 = 0.843303571429, recall_at_1 = 0.373214285714, loss = 0.617763, recall_at_10 = 1.0, recall_at_2 = 0.559375.\n",
      "INFO:tensorflow:Results after 150 steps (8.337 sec/batch): recall_at_5 = 0.844583333333, recall_at_1 = 0.376666666667, loss = 0.617761, recall_at_10 = 1.0, recall_at_2 = 0.562083333333.\n",
      "INFO:tensorflow:Results after 160 steps (6.140 sec/batch): recall_at_5 = 0.842578125, recall_at_1 = 0.375, loss = 0.615079, recall_at_10 = 1.0, recall_at_2 = 0.5609375.\n",
      "INFO:tensorflow:Results after 170 steps (6.139 sec/batch): recall_at_5 = 0.839705882353, recall_at_1 = 0.373897058824, loss = 0.579799, recall_at_10 = 1.0, recall_at_2 = 0.560661764706.\n",
      "INFO:tensorflow:Results after 180 steps (6.466 sec/batch): recall_at_5 = 0.839236111111, recall_at_1 = 0.371875, loss = 0.623453, recall_at_10 = 1.0, recall_at_2 = 0.559722222222.\n",
      "INFO:tensorflow:Results after 190 steps (6.147 sec/batch): recall_at_5 = 0.837171052632, recall_at_1 = 0.370723684211, loss = 0.609511, recall_at_10 = 1.0, recall_at_2 = 0.559210526316.\n",
      "INFO:tensorflow:Results after 200 steps (6.063 sec/batch): recall_at_5 = 0.8375, recall_at_1 = 0.3703125, loss = 0.662566, recall_at_10 = 1.0, recall_at_2 = 0.5596875.\n",
      "INFO:tensorflow:Results after 210 steps (6.254 sec/batch): recall_at_5 = 0.839583333333, recall_at_1 = 0.371726190476, loss = 0.599779, recall_at_10 = 1.0, recall_at_2 = 0.5625.\n",
      "INFO:tensorflow:Results after 220 steps (5.949 sec/batch): recall_at_5 = 0.839488636364, recall_at_1 = 0.369602272727, loss = 0.58807, recall_at_10 = 1.0, recall_at_2 = 0.5625.\n",
      "INFO:tensorflow:Results after 230 steps (5.961 sec/batch): recall_at_5 = 0.839130434783, recall_at_1 = 0.369565217391, loss = 0.515266, recall_at_10 = 1.0, recall_at_2 = 0.561413043478.\n",
      "INFO:tensorflow:Results after 240 steps (6.499 sec/batch): recall_at_5 = 0.838802083333, recall_at_1 = 0.3703125, loss = 0.544863, recall_at_10 = 1.0, recall_at_2 = 0.561458333333.\n",
      "INFO:tensorflow:Results after 250 steps (5.985 sec/batch): recall_at_5 = 0.83825, recall_at_1 = 0.3705, loss = 0.61235, recall_at_10 = 1.0, recall_at_2 = 0.56125.\n",
      "INFO:tensorflow:Results after 260 steps (6.043 sec/batch): recall_at_5 = 0.838461538462, recall_at_1 = 0.370913461538, loss = 0.590486, recall_at_10 = 1.0, recall_at_2 = 0.562259615385.\n",
      "INFO:tensorflow:Results after 270 steps (6.028 sec/batch): recall_at_5 = 0.840046296296, recall_at_1 = 0.373148148148, loss = 0.572281, recall_at_10 = 1.0, recall_at_2 = 0.563888888889.\n",
      "INFO:tensorflow:Results after 280 steps (5.845 sec/batch): recall_at_5 = 0.839732142857, recall_at_1 = 0.372321428571, loss = 0.568462, recall_at_10 = 1.0, recall_at_2 = 0.565625.\n",
      "INFO:tensorflow:Results after 290 steps (6.043 sec/batch): recall_at_5 = 0.840732758621, recall_at_1 = 0.374784482759, loss = 0.510054, recall_at_10 = 1.0, recall_at_2 = 0.567672413793.\n",
      "INFO:tensorflow:Results after 300 steps (6.482 sec/batch): recall_at_5 = 0.84, recall_at_1 = 0.375416666667, loss = 0.596875, recall_at_10 = 1.0, recall_at_2 = 0.568541666667.\n",
      "INFO:tensorflow:Results after 310 steps (5.922 sec/batch): recall_at_5 = 0.839717741935, recall_at_1 = 0.373991935484, loss = 0.620664, recall_at_10 = 1.0, recall_at_2 = 0.565322580645.\n",
      "INFO:tensorflow:Results after 320 steps (5.916 sec/batch): recall_at_5 = 0.8408203125, recall_at_1 = 0.375390625, loss = 0.626089, recall_at_10 = 1.0, recall_at_2 = 0.56484375.\n",
      "INFO:tensorflow:Results after 330 steps (6.254 sec/batch): recall_at_5 = 0.841098484848, recall_at_1 = 0.374242424242, loss = 0.607789, recall_at_10 = 1.0, recall_at_2 = 0.566287878788.\n",
      "INFO:tensorflow:Results after 340 steps (6.278 sec/batch): recall_at_5 = 0.841176470588, recall_at_1 = 0.375183823529, loss = 0.615751, recall_at_10 = 1.0, recall_at_2 = 0.566727941176.\n",
      "INFO:tensorflow:Results after 350 steps (6.055 sec/batch): recall_at_5 = 0.840535714286, recall_at_1 = 0.373392857143, loss = 0.645873, recall_at_10 = 1.0, recall_at_2 = 0.565892857143.\n",
      "INFO:tensorflow:Results after 360 steps (6.356 sec/batch): recall_at_5 = 0.841145833333, recall_at_1 = 0.373784722222, loss = 0.63788, recall_at_10 = 1.0, recall_at_2 = 0.565451388889.\n",
      "INFO:tensorflow:Results after 370 steps (6.420 sec/batch): recall_at_5 = 0.841554054054, recall_at_1 = 0.374155405405, loss = 0.556901, recall_at_10 = 1.0, recall_at_2 = 0.565878378378.\n",
      "INFO:tensorflow:Results after 380 steps (5.853 sec/batch): recall_at_5 = 0.840789473684, recall_at_1 = 0.374835526316, loss = 0.547165, recall_at_10 = 1.0, recall_at_2 = 0.565953947368.\n",
      "INFO:tensorflow:Results after 390 steps (5.796 sec/batch): recall_at_5 = 0.840224358974, recall_at_1 = 0.373237179487, loss = 0.582239, recall_at_10 = 1.0, recall_at_2 = 0.564743589744.\n",
      "INFO:tensorflow:Results after 400 steps (6.100 sec/batch): recall_at_5 = 0.83953125, recall_at_1 = 0.371875, loss = 0.622936, recall_at_10 = 1.0, recall_at_2 = 0.56359375.\n",
      "INFO:tensorflow:Results after 410 steps (6.151 sec/batch): recall_at_5 = 0.840853658537, recall_at_1 = 0.370426829268, loss = 0.585681, recall_at_10 = 1.0, recall_at_2 = 0.563414634146.\n",
      "INFO:tensorflow:Results after 420 steps (6.802 sec/batch): recall_at_5 = 0.839880952381, recall_at_1 = 0.368898809524, loss = 0.643031, recall_at_10 = 1.0, recall_at_2 = 0.562351190476.\n",
      "INFO:tensorflow:Results after 430 steps (6.076 sec/batch): recall_at_5 = 0.839389534884, recall_at_1 = 0.368168604651, loss = 0.597804, recall_at_10 = 1.0, recall_at_2 = 0.560901162791.\n",
      "INFO:tensorflow:Results after 440 steps (6.242 sec/batch): recall_at_5 = 0.839772727273, recall_at_1 = 0.368607954545, loss = 0.565282, recall_at_10 = 1.0, recall_at_2 = 0.562357954545.\n",
      "INFO:tensorflow:Results after 450 steps (6.410 sec/batch): recall_at_5 = 0.840138888889, recall_at_1 = 0.369444444444, loss = 0.644584, recall_at_10 = 1.0, recall_at_2 = 0.562361111111.\n",
      "INFO:tensorflow:Results after 460 steps (6.638 sec/batch): recall_at_5 = 0.840625, recall_at_1 = 0.368614130435, loss = 0.682284, recall_at_10 = 1.0, recall_at_2 = 0.561277173913.\n",
      "INFO:tensorflow:Results after 470 steps (6.107 sec/batch): recall_at_5 = 0.840159574468, recall_at_1 = 0.36875, loss = 0.699053, recall_at_10 = 1.0, recall_at_2 = 0.561170212766.\n",
      "INFO:tensorflow:Results after 480 steps (6.016 sec/batch): recall_at_5 = 0.839192708333, recall_at_1 = 0.369010416667, loss = 0.693082, recall_at_10 = 1.0, recall_at_2 = 0.5609375.\n",
      "INFO:tensorflow:Results after 490 steps (6.360 sec/batch): recall_at_5 = 0.839540816327, recall_at_1 = 0.368367346939, loss = 0.621986, recall_at_10 = 1.0, recall_at_2 = 0.560204081633.\n",
      "INFO:tensorflow:Results after 500 steps (5.789 sec/batch): recall_at_5 = 0.8395, recall_at_1 = 0.36825, loss = 0.586281, recall_at_10 = 1.0, recall_at_2 = 0.560875.\n",
      "INFO:tensorflow:Results after 510 steps (6.095 sec/batch): recall_at_5 = 0.840196078431, recall_at_1 = 0.367892156863, loss = 0.567148, recall_at_10 = 1.0, recall_at_2 = 0.560539215686.\n",
      "INFO:tensorflow:Results after 520 steps (6.408 sec/batch): recall_at_5 = 0.839423076923, recall_at_1 = 0.367908653846, loss = 0.624726, recall_at_10 = 1.0, recall_at_2 = 0.560697115385.\n",
      "INFO:tensorflow:Results after 530 steps (6.334 sec/batch): recall_at_5 = 0.838089622642, recall_at_1 = 0.366273584906, loss = 0.645334, recall_at_10 = 1.0, recall_at_2 = 0.558962264151.\n",
      "INFO:tensorflow:Results after 540 steps (6.225 sec/batch): recall_at_5 = 0.838310185185, recall_at_1 = 0.366203703704, loss = 0.628576, recall_at_10 = 1.0, recall_at_2 = 0.55787037037.\n",
      "INFO:tensorflow:Results after 550 steps (6.944 sec/batch): recall_at_5 = 0.837272727273, recall_at_1 = 0.365909090909, loss = 0.564111, recall_at_10 = 1.0, recall_at_2 = 0.556704545455.\n",
      "INFO:tensorflow:Results after 560 steps (6.176 sec/batch): recall_at_5 = 0.837611607143, recall_at_1 = 0.366183035714, loss = 0.653838, recall_at_10 = 1.0, recall_at_2 = 0.557142857143.\n",
      "INFO:tensorflow:Results after 570 steps (7.067 sec/batch): recall_at_5 = 0.837390350877, recall_at_1 = 0.367214912281, loss = 0.547975, recall_at_10 = 1.0, recall_at_2 = 0.557675438596.\n",
      "INFO:tensorflow:Results after 580 steps (6.708 sec/batch): recall_at_5 = 0.8375, recall_at_1 = 0.367456896552, loss = 0.641165, recall_at_10 = 1.0, recall_at_2 = 0.55775862069.\n",
      "INFO:tensorflow:Results after 590 steps (6.467 sec/batch): recall_at_5 = 0.837605932203, recall_at_1 = 0.367161016949, loss = 0.666839, recall_at_10 = 1.0, recall_at_2 = 0.557097457627.\n",
      "INFO:tensorflow:Results after 600 steps (7.580 sec/batch): recall_at_5 = 0.837604166667, recall_at_1 = 0.368020833333, loss = 0.604327, recall_at_10 = 1.0, recall_at_2 = 0.557395833333.\n",
      "INFO:tensorflow:Results after 610 steps (6.199 sec/batch): recall_at_5 = 0.838114754098, recall_at_1 = 0.368852459016, loss = 0.588714, recall_at_10 = 1.0, recall_at_2 = 0.558094262295.\n",
      "INFO:tensorflow:Results after 620 steps (6.238 sec/batch): recall_at_5 = 0.838004032258, recall_at_1 = 0.368850806452, loss = 0.633422, recall_at_10 = 1.0, recall_at_2 = 0.558266129032.\n",
      "INFO:tensorflow:Results after 630 steps (6.243 sec/batch): recall_at_5 = 0.837400793651, recall_at_1 = 0.369047619048, loss = 0.590239, recall_at_10 = 1.0, recall_at_2 = 0.558035714286.\n",
      "INFO:tensorflow:Results after 640 steps (6.308 sec/batch): recall_at_5 = 0.83798828125, recall_at_1 = 0.3697265625, loss = 0.541603, recall_at_10 = 1.0, recall_at_2 = 0.5583984375.\n",
      "INFO:tensorflow:Results after 650 steps (6.701 sec/batch): recall_at_5 = 0.837788461538, recall_at_1 = 0.370096153846, loss = 0.53728, recall_at_10 = 1.0, recall_at_2 = 0.558076923077.\n",
      "INFO:tensorflow:Results after 660 steps (6.502 sec/batch): recall_at_5 = 0.8375, recall_at_1 = 0.369696969697, loss = 0.681919, recall_at_10 = 1.0, recall_at_2 = 0.557291666667.\n",
      "INFO:tensorflow:Results after 670 steps (6.250 sec/batch): recall_at_5 = 0.837873134328, recall_at_1 = 0.369029850746, loss = 0.687242, recall_at_10 = 1.0, recall_at_2 = 0.557369402985.\n",
      "INFO:tensorflow:Results after 680 steps (6.166 sec/batch): recall_at_5 = 0.837683823529, recall_at_1 = 0.368474264706, loss = 0.564918, recall_at_10 = 1.0, recall_at_2 = 0.556985294118.\n",
      "INFO:tensorflow:Results after 690 steps (6.342 sec/batch): recall_at_5 = 0.83777173913, recall_at_1 = 0.367481884058, loss = 0.693276, recall_at_10 = 1.0, recall_at_2 = 0.55615942029.\n",
      "INFO:tensorflow:Results after 700 steps (6.667 sec/batch): recall_at_5 = 0.837410714286, recall_at_1 = 0.367232142857, loss = 0.579196, recall_at_10 = 1.0, recall_at_2 = 0.555357142857.\n",
      "INFO:tensorflow:Results after 710 steps (6.516 sec/batch): recall_at_5 = 0.836883802817, recall_at_1 = 0.367429577465, loss = 0.621945, recall_at_10 = 1.0, recall_at_2 = 0.55536971831.\n",
      "INFO:tensorflow:Results after 720 steps (5.923 sec/batch): recall_at_5 = 0.837586805556, recall_at_1 = 0.367621527778, loss = 0.708331, recall_at_10 = 1.0, recall_at_2 = 0.555208333333.\n",
      "INFO:tensorflow:Results after 730 steps (5.949 sec/batch): recall_at_5 = 0.837414383562, recall_at_1 = 0.367465753425, loss = 0.612156, recall_at_10 = 1.0, recall_at_2 = 0.555650684932.\n",
      "INFO:tensorflow:Results after 740 steps (6.113 sec/batch): recall_at_5 = 0.838344594595, recall_at_1 = 0.367060810811, loss = 0.676808, recall_at_10 = 1.0, recall_at_2 = 0.555236486486.\n",
      "INFO:tensorflow:Results after 750 steps (6.543 sec/batch): recall_at_5 = 0.838333333333, recall_at_1 = 0.3665, loss = 0.540351, recall_at_10 = 1.0, recall_at_2 = 0.55475.\n",
      "INFO:tensorflow:Results after 760 steps (6.222 sec/batch): recall_at_5 = 0.838898026316, recall_at_1 = 0.366447368421, loss = 0.579706, recall_at_10 = 1.0, recall_at_2 = 0.5546875.\n",
      "INFO:tensorflow:Results after 770 steps (6.227 sec/batch): recall_at_5 = 0.837824675325, recall_at_1 = 0.366964285714, loss = 0.669819, recall_at_10 = 1.0, recall_at_2 = 0.554464285714.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 udc_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python udc_test.py --model_dir=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\t\t     model.ckpt-5795.meta\r\n",
      "events.out.tfevents.1468168956.07a2d3d953a6  model.ckpt-5874-00000-of-00001\r\n",
      "events.out.tfevents.1468200751.07a2d3d953a6  model.ckpt-5874.meta\r\n",
      "graph.pbtxt\t\t\t\t     model.ckpt-5957-00000-of-00001\r\n",
      "model.ckpt-5713-00000-of-00001\t\t     model.ckpt-5957.meta\r\n",
      "model.ckpt-5713.meta\t\t\t     model.ckpt-6001-00000-of-00001\r\n",
      "model.ckpt-5795-00000-of-00001\t\t     model.ckpt-6001.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls runs/1468168955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Restored model from /root/work/chatbot-retrieval/runs/1468168955/model.ckpt-6001-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 6001.\n",
      "INFO:tensorflow:Results after 10 steps (5.981 sec/batch): recall_at_2 = 0.51875, recall_at_5 = 0.84375, loss = 0.572061, recall_at_1 = 0.34375, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 20 steps (5.865 sec/batch): recall_at_2 = 0.521875, recall_at_5 = 0.853125, loss = 0.52984, recall_at_1 = 0.346875, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 30 steps (5.801 sec/batch): recall_at_2 = 0.5375, recall_at_5 = 0.866666666667, loss = 0.636007, recall_at_1 = 0.3625, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 40 steps (5.775 sec/batch): recall_at_2 = 0.540625, recall_at_5 = 0.853125, loss = 0.548822, recall_at_1 = 0.3671875, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 50 steps (5.924 sec/batch): recall_at_2 = 0.535, recall_at_5 = 0.8525, loss = 0.470671, recall_at_1 = 0.35625, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 60 steps (5.849 sec/batch): recall_at_2 = 0.536458333333, recall_at_5 = 0.855208333333, loss = 0.560469, recall_at_1 = 0.35625, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 70 steps (6.502 sec/batch): recall_at_2 = 0.53125, recall_at_5 = 0.858035714286, loss = 0.671933, recall_at_1 = 0.351785714286, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 80 steps (5.806 sec/batch): recall_at_2 = 0.53046875, recall_at_5 = 0.853125, loss = 0.467002, recall_at_1 = 0.3484375, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 90 steps (5.803 sec/batch): recall_at_2 = 0.527777777778, recall_at_5 = 0.853472222222, loss = 0.511545, recall_at_1 = 0.35, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 100 steps (5.793 sec/batch): recall_at_2 = 0.530625, recall_at_5 = 0.848125, loss = 0.591843, recall_at_1 = 0.350625, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 110 steps (5.850 sec/batch): recall_at_2 = 0.536931818182, recall_at_5 = 0.847159090909, loss = 0.60818, recall_at_1 = 0.360795454545, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 120 steps (5.878 sec/batch): recall_at_2 = 0.534375, recall_at_5 = 0.840625, loss = 0.561525, recall_at_1 = 0.360416666667, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 130 steps (5.855 sec/batch): recall_at_2 = 0.536538461538, recall_at_5 = 0.838461538462, loss = 0.524436, recall_at_1 = 0.360096153846, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 140 steps (5.788 sec/batch): recall_at_2 = 0.539285714286, recall_at_5 = 0.839285714286, loss = 0.484702, recall_at_1 = 0.361607142857, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 150 steps (5.903 sec/batch): recall_at_2 = 0.543333333333, recall_at_5 = 0.8425, loss = 0.617036, recall_at_1 = 0.364166666667, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 160 steps (5.817 sec/batch): recall_at_2 = 0.550390625, recall_at_5 = 0.84453125, loss = 0.49092, recall_at_1 = 0.36953125, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 170 steps (5.827 sec/batch): recall_at_2 = 0.552573529412, recall_at_5 = 0.844485294118, loss = 0.556329, recall_at_1 = 0.373161764706, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 180 steps (6.031 sec/batch): recall_at_2 = 0.553472222222, recall_at_5 = 0.840625, loss = 0.565366, recall_at_1 = 0.371180555556, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 190 steps (5.817 sec/batch): recall_at_2 = 0.551315789474, recall_at_5 = 0.840789473684, loss = 0.560238, recall_at_1 = 0.371381578947, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 200 steps (5.859 sec/batch): recall_at_2 = 0.55, recall_at_5 = 0.8403125, loss = 0.563665, recall_at_1 = 0.3725, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 210 steps (6.333 sec/batch): recall_at_2 = 0.551488095238, recall_at_5 = 0.842261904762, loss = 0.531956, recall_at_1 = 0.375297619048, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 220 steps (5.766 sec/batch): recall_at_2 = 0.551420454545, recall_at_5 = 0.843181818182, loss = 0.53365, recall_at_1 = 0.374147727273, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 230 steps (5.851 sec/batch): recall_at_2 = 0.551630434783, recall_at_5 = 0.84375, loss = 0.563878, recall_at_1 = 0.372826086957, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 240 steps (5.814 sec/batch): recall_at_2 = 0.55078125, recall_at_5 = 0.843489583333, loss = 0.489899, recall_at_1 = 0.371354166667, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 250 steps (6.041 sec/batch): recall_at_2 = 0.55125, recall_at_5 = 0.84275, loss = 0.538377, recall_at_1 = 0.37275, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 260 steps (6.124 sec/batch): recall_at_2 = 0.551682692308, recall_at_5 = 0.842067307692, loss = 0.630551, recall_at_1 = 0.372355769231, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 270 steps (6.203 sec/batch): recall_at_2 = 0.553935185185, recall_at_5 = 0.843981481481, loss = 0.553513, recall_at_1 = 0.375231481481, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 280 steps (5.915 sec/batch): recall_at_2 = 0.5546875, recall_at_5 = 0.84375, loss = 0.589647, recall_at_1 = 0.375892857143, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 290 steps (6.067 sec/batch): recall_at_2 = 0.555387931034, recall_at_5 = 0.844827586207, loss = 0.552154, recall_at_1 = 0.377801724138, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 300 steps (6.001 sec/batch): recall_at_2 = 0.554791666667, recall_at_5 = 0.842916666667, loss = 0.520591, recall_at_1 = 0.377291666667, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 310 steps (6.165 sec/batch): recall_at_2 = 0.555846774194, recall_at_5 = 0.844556451613, loss = 0.506557, recall_at_1 = 0.377822580645, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 320 steps (6.264 sec/batch): recall_at_2 = 0.555859375, recall_at_5 = 0.84453125, loss = 0.494366, recall_at_1 = 0.3763671875, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 330 steps (5.925 sec/batch): recall_at_2 = 0.55321969697, recall_at_5 = 0.843181818182, loss = 0.541587, recall_at_1 = 0.373863636364, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 340 steps (6.185 sec/batch): recall_at_2 = 0.553676470588, recall_at_5 = 0.843014705882, loss = 0.535219, recall_at_1 = 0.373529411765, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 350 steps (6.260 sec/batch): recall_at_2 = 0.552857142857, recall_at_5 = 0.843392857143, loss = 0.527072, recall_at_1 = 0.373035714286, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 360 steps (6.048 sec/batch): recall_at_2 = 0.554166666667, recall_at_5 = 0.843576388889, loss = 0.482158, recall_at_1 = 0.372222222222, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 370 steps (6.239 sec/batch): recall_at_2 = 0.554898648649, recall_at_5 = 0.845101351351, loss = 0.528336, recall_at_1 = 0.373141891892, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 380 steps (6.266 sec/batch): recall_at_2 = 0.553618421053, recall_at_5 = 0.844736842105, loss = 0.535785, recall_at_1 = 0.371217105263, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 390 steps (6.294 sec/batch): recall_at_2 = 0.554326923077, recall_at_5 = 0.844391025641, loss = 0.553631, recall_at_1 = 0.370993589744, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 400 steps (6.228 sec/batch): recall_at_2 = 0.5559375, recall_at_5 = 0.84515625, loss = 0.516336, recall_at_1 = 0.37234375, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 410 steps (6.279 sec/batch): recall_at_2 = 0.554115853659, recall_at_5 = 0.84375, loss = 0.582832, recall_at_1 = 0.37012195122, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 420 steps (6.005 sec/batch): recall_at_2 = 0.55431547619, recall_at_5 = 0.843303571429, loss = 0.608166, recall_at_1 = 0.36994047619, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 430 steps (6.380 sec/batch): recall_at_2 = 0.554069767442, recall_at_5 = 0.84273255814, loss = 0.53077, recall_at_1 = 0.370348837209, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 440 steps (6.444 sec/batch): recall_at_2 = 0.554403409091, recall_at_5 = 0.84375, loss = 0.501665, recall_at_1 = 0.371448863636, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 450 steps (6.272 sec/batch): recall_at_2 = 0.553888888889, recall_at_5 = 0.842916666667, loss = 0.581986, recall_at_1 = 0.371527777778, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 460 steps (7.902 sec/batch): recall_at_2 = 0.553125, recall_at_5 = 0.843342391304, loss = 0.573348, recall_at_1 = 0.370244565217, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 470 steps (5.876 sec/batch): recall_at_2 = 0.553590425532, recall_at_5 = 0.843218085106, loss = 0.577356, recall_at_1 = 0.369946808511, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 480 steps (5.963 sec/batch): recall_at_2 = 0.554036458333, recall_at_5 = 0.843880208333, loss = 0.549901, recall_at_1 = 0.370052083333, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 490 steps (6.298 sec/batch): recall_at_2 = 0.552168367347, recall_at_5 = 0.843494897959, loss = 0.546825, recall_at_1 = 0.368112244898, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 500 steps (5.812 sec/batch): recall_at_2 = 0.55225, recall_at_5 = 0.8435, loss = 0.520749, recall_at_1 = 0.36775, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 510 steps (6.767 sec/batch): recall_at_2 = 0.551838235294, recall_at_5 = 0.843995098039, loss = 0.554377, recall_at_1 = 0.367647058824, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 520 steps (6.363 sec/batch): recall_at_2 = 0.550480769231, recall_at_5 = 0.843990384615, loss = 0.524804, recall_at_1 = 0.365985576923, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 530 steps (7.214 sec/batch): recall_at_2 = 0.550825471698, recall_at_5 = 0.844103773585, loss = 0.5555, recall_at_1 = 0.365683962264, recall_at_10 = 1.0.\n",
      "INFO:tensorflow:Results after 540 steps (6.707 sec/batch): recall_at_2 = 0.551273148148, recall_at_5 = 0.84375, loss = 0.568389, recall_at_1 = 0.365162037037, recall_at_10 = 1.0.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 udc_test.py --model_dir=runs/1468168955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python udc_predict.py --model_dir=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Example context\n",
      "Response 1: 0.634551\n",
      "Response 2: 0.64461\n"
     ]
    }
   ],
   "source": [
    "!python3 udc_predict.py --model_dir=runs/1468168955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] DEEP LEARNING FOR CHATBOTS, PART 1 – INTRODUCTION - http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/\n",
    "* [2] DEEP LEARNING FOR CHATBOTS, PART 2 – IMPLEMENTING A RETRIEVAL-BASED MODEL IN TENSORFLOW - http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/\n",
    "* [3] Chapter 8. Evaluation (Statistical Machine Translation) - http://www.statmt.org/book/slides/08-evaluation.pdf\n",
    "* [4] BLEU (wikipedia) - https://en.wikipedia.org/wiki/BLEU\n",
    "* [5] BLEU (\"Show and Tell: A Neural Image Caption Generator (CVPR 2015) slide\") - https://docs.com/hana-lee/7849/show-and-tell-a-neural-image-caption-generator\n",
    "* [6] BLEU (5. blue slide) - http://www.slideshare.net/hiroshimatsumoto750/5-bleu\n",
    "* [7] Source code for nltk.align.bleu - http://www.nltk.org/_modules/nltk/align/bleu.html\n",
    "* [8] code - https://github.com/dennybritz/chatbot-retrieval/\n",
    "* [9] data - https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
